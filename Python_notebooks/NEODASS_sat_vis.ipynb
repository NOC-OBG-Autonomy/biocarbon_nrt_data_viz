{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib.colors as colors\n",
    "import geopandas as gpd\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from glob import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import sys\n",
    "import math\n",
    "from geopy.distance import distance\n",
    "from matplotlib.colors import to_rgba\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish directory locations \n",
    "\n",
    "parent_dir    = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir      = os.path.join(parent_dir, 'data')\n",
    "satellite_dir = os.path.join(data_dir, 'satellite')\n",
    "output_dir    = os.path.join(parent_dir, 'Output/sat_plot')\n",
    "NEODASS_dir   = os.path.join(satellite_dir, 'NEODASS')\n",
    "floats_dir    = os.path.join(parent_dir, 'Data/Floats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting preferences\n",
    "\n",
    "# Global\n",
    "min_lon = -35\n",
    "max_lon = -5\n",
    "min_lat = 55\n",
    "max_lat = 66\n",
    "\n",
    "# Float colors\n",
    "# For additional floats, add the name (as it appears in the 'Float_positions.csv') and color you'd like (as a hexcode)\n",
    "float_colors = {\n",
    "        '4903532':  '#B4184C',\n",
    "        'navis102': '#F5A300',\n",
    "        '1902637':  '#0000E0',\n",
    "        'navis101': '#FBFF1F'}\n",
    "\n",
    "# CHLA\n",
    "CHLA_color           = 'YlGnBu_r'\n",
    "CHLA_plot_as_log     = True # Default True\n",
    "CHLA_plot_lim_max    = 10   # Default 10\n",
    "CHLA_plot_lim_min    = 0.1  # Default 0.1\n",
    "\n",
    "# SST\n",
    "SST_color            = 'YlOrRd'\n",
    "SST_plot_as_log      = False # Default False\n",
    "SST_plot_lim_max     = 15    # Default 15\n",
    "SST_plot_lim_min     = 5     # Default 5\n",
    "\n",
    "# SSH\n",
    "SSH_color            = 'RdBu'\n",
    "SSH_plot_as_log      = False # Default False\n",
    "SSH_plot_lim_max     = 0.5   # Default  0.5\n",
    "SSH_plot_lim_min     = -0.5  # Default -0.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate points on a circle centered at (lat, lon) with a given radius\n",
    "def generate_circle_points(lat, lon, radius_km, num_points=360):\n",
    "    angles = np.linspace(0, 360, num_points)\n",
    "    circle_points = []\n",
    "    for angle in angles:\n",
    "        point = distance(kilometers=radius_km).destination((lat, lon), angle)\n",
    "        circle_points.append((point.latitude, point.longitude))\n",
    "    \n",
    "    return np.array(circle_points)\n",
    "\n",
    "first_line_path  = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\data\\\\bathymetry\\\\ne_10m_bathymetry_J_1000.shp'\n",
    "second_line_path = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\data\\\\bathymetry\\\\ne_10m_bathymetry_I_2000.shp'\n",
    "\n",
    "gdf_1000 = gpd.read_file(first_line_path)\n",
    "gdf_2000 = gpd.read_file(second_line_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cmems_sea_level-sla-1d-20240527_20240527-nrt.nc', 'olci_a_1km-CHL_OC4ME-1d-20240527_20240527-nrt.nc', 'olci_b_1km-CHL_OC4ME-1d-20240527_20240527-nrt.nc', 'slstr_a-sea_surface_temperature-1d-20240527_20240527-nrt.nc', 'slstr_b-sea_surface_temperature-1d-20240527_20240527-nrt.nc', 'viirs_noaa20-chl_oc5ci-1d-20240527_20240527-nrt.nc', 'viirs_suomi-chl_oc5_pic-1d-20240527_20240527-nrt.nc']\n",
      "File: cmems_sea_level-sla-1d-20240527_20240527-nrt.nc\n",
      "Base Name: cmems_sea_level-sla-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: sla\n",
      "File: olci_a_1km-CHL_OC4ME-1d-20240527_20240527-nrt.nc\n",
      "Base Name: olci__1km-CHL_OC4ME-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: CHL_OC4ME\n",
      "File: olci_b_1km-CHL_OC4ME-1d-20240527_20240527-nrt.nc\n",
      "Base Name: olci__1km-CHL_OC4ME-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: CHL_OC4ME\n",
      "File: slstr_a-sea_surface_temperature-1d-20240527_20240527-nrt.nc\n",
      "Base Name: slstr_-sea_surface_temperature-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: sea_surface_temperature\n",
      "File: slstr_b-sea_surface_temperature-1d-20240527_20240527-nrt.nc\n",
      "Base Name: slstr_-sea_surface_temperature-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: sea_surface_temperature\n",
      "File: viirs_noaa20-chl_oc5ci-1d-20240527_20240527-nrt.nc\n",
      "Base Name: viirs_noaa20-chl_oc5ci-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: chl_oc5ci\n",
      "File: viirs_suomi-chl_oc5_pic-1d-20240527_20240527-nrt.nc\n",
      "Base Name: viirs_suomi-chl_oc5_pic-1d-20240527_20240527-nrt.nc\n",
      "Key Variable: chl_oc5\n"
     ]
    }
   ],
   "source": [
    "### Plotting most recent data from NEODASS\n",
    "\n",
    "## List most recent files\n",
    "\n",
    "# Get yesterday's date in the required format\n",
    "yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "# List to store matching file names\n",
    "matching_files = []\n",
    "\n",
    "# Loop through the files in the directory\n",
    "for filename in os.listdir(NEODASS_dir):\n",
    "    if filename.endswith('.nc') and f'-1d-{yesterday}_{yesterday}-' in filename:\n",
    "        matching_files.append(filename)\n",
    "\n",
    "print(matching_files)\n",
    "\n",
    "## List variables from these files\n",
    "\n",
    "# Dictionary to store files by their base names (excluding '_a_' or '_b_') and key variables\n",
    "file_dict = {}\n",
    "\n",
    "for file in matching_files:\n",
    "    # Identify the base name by removing '_a' or '_b' if present\n",
    "    base_name = file.replace('_a', '_').replace('_b', '_')\n",
    "    if base_name not in file_dict:\n",
    "        file_dict[base_name] = {}\n",
    "    filepath  = os.path.join(NEODASS_dir, file)\n",
    "    ds        = xr.open_dataset(filepath)\n",
    "    variables = list(ds.data_vars.keys())\n",
    "    \n",
    "    # Find the key variable excluding 'longitude' and 'latitude'\n",
    "    key_variable = None\n",
    "    for var in variables:\n",
    "        if 'longitude' not in var.lower() and 'latitude' not in var.lower():\n",
    "            key_variable = var\n",
    "            break\n",
    "    \n",
    "    if key_variable:\n",
    "        file_dict[base_name][file] = key_variable\n",
    "    \n",
    "    ds.close()\n",
    "\n",
    "# Print the results\n",
    "for base_name, files in file_dict.items():\n",
    "    for file, key_variable in files.items():\n",
    "        print(f'File: {file}')\n",
    "        print(f'Base Name: {base_name}')\n",
    "        print(f'Key Variable: {key_variable}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanshil\\AppData\\Local\\Temp\\ipykernel_14596\\1656339745.py:34: RuntimeWarning: Mean of empty slice\n",
      "  combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n",
      "C:\\Users\\hanshil\\AppData\\Local\\Temp\\ipykernel_14596\\1656339745.py:34: RuntimeWarning: Mean of empty slice\n",
      "  combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Plotting loops\n",
    "\n",
    "# 130km circle around deploy point\n",
    "circle_points = generate_circle_points(60, -24, 130)\n",
    "circle_lats, circle_lons = circle_points[:, 0], circle_points[:, 1]\n",
    "\n",
    "# Load float positions\n",
    "float_position_path = os.path.join(floats_dir, 'Float_positions_2024_05_25.csv')\n",
    "full_position = pd.read_csv(float_position_path)\n",
    "\n",
    "for base_name, files in file_dict.items():\n",
    "\n",
    "    # Check if there are multiple files associated with the base name\n",
    "    if len(files) > 1:\n",
    "\n",
    "        # List of data variables to be combined\n",
    "        data_vars = []\n",
    "        \n",
    "        # Loop through each file and collect data variables\n",
    "        for file, data_var in files.items():\n",
    "            # Perform data preparation for files with the same base name\n",
    "            cur_data_var = xr.open_dataset(os.path.join(NEODASS_dir, f'{file}'))\n",
    "            data_vars.append(cur_data_var[data_var])\n",
    "        \n",
    "        # Align data variables from all files\n",
    "        aligned_data_vars = xr.align(*data_vars, join='outer')\n",
    "        \n",
    "        # Combine aligned data variables\n",
    "        combined_data_var = aligned_data_vars[0]\n",
    "        for var in aligned_data_vars[1:]:\n",
    "            combined_data_var      = combined_data_var.combine_first(var)\n",
    "            combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n",
    "            date_of_plot = str(combined_data_var['time'].data[0])[:10]\n",
    "            \n",
    "    else: # Single satellite file\n",
    "\n",
    "        for file, data_var in files.items():   \n",
    "            cur_data_var = xr.open_dataset(os.path.join(NEODASS_dir, f'{file}'))\n",
    "            date_of_plot = str(cur_data_var['time'].data[0])[:10]\n",
    "\n",
    "    # Initialise figure\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax  = fig.add_subplot(1, 1, 1, projection=ccrs.Mercator())\n",
    "    ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Set plot settings based on variable\n",
    "    var_name_lower = data_var.lower()\n",
    "    if 'chl' in var_name_lower:\n",
    "        units_nonstandard = cur_data_var[data_var].attrs.get('units_nonstandard')\n",
    "        xx_plot_cbar_label = 'Chlorophyll (' + units_nonstandard + ')'\n",
    "        xx_plot_min = CHLA_plot_lim_min\n",
    "        xx_plot_max = CHLA_plot_lim_max\n",
    "        color       = CHLA_color\n",
    "        log_scaling = CHLA_plot_as_log\n",
    "        xx_output_dir_name = 'Chla'\n",
    "    elif 'temp' in var_name_lower:\n",
    "        units_nonstandard = cur_data_var[data_var].attrs.get('units_nonstandard')\n",
    "        if units_nonstandard == 'kelvin':\n",
    "            degree_sign = u'\\N{DEGREE SIGN}'\n",
    "            xx_plot_cbar_label = 'Sea Surface Temperature ('+degree_sign+'C)'\n",
    "            if len(files) > 1:\n",
    "                combined_data_var_mean -= 273.15\n",
    "            else:\n",
    "                cur_data_var[data_var] = cur_data_var[data_var] - 273.15 # Convert from Kelvin to Celsius\n",
    "            xx_plot_min = SST_plot_lim_min\n",
    "            xx_plot_max = SST_plot_lim_max\n",
    "            color       = SST_color\n",
    "            log_scaling = SST_plot_as_log\n",
    "            xx_output_dir_name = 'SST'\n",
    "    elif 'sla' in var_name_lower:\n",
    "        units_nonstandard = cur_data_var[data_var].attrs.get('units')\n",
    "        xx_plot_cbar_label = 'Sea level anamoly (' + units_nonstandard + ')'\n",
    "        xx_plot_min = SSH_plot_lim_min\n",
    "        xx_plot_max = SSH_plot_lim_max\n",
    "        color       = SSH_color\n",
    "        log_scaling = SSH_plot_as_log\n",
    "        xx_output_dir_name = 'SLA'\n",
    "    if log_scaling:\n",
    "        norm = colors.LogNorm(vmin = xx_plot_min, vmax = xx_plot_max)\n",
    "    else:\n",
    "        norm = colors.Normalize(vmin = xx_plot_min, vmax = xx_plot_max)\n",
    "\n",
    "    if len(files) > 1:\n",
    "    # Clip data for clean colormap\n",
    "        NEODASS_data_to_plot_1day = np.clip(combined_data_var_mean.data,xx_plot_min,xx_plot_max)\n",
    "    else:\n",
    "        NEODASS_data_to_plot_1day = np.clip(cur_data_var[data_var].data[0,:],xx_plot_min,xx_plot_max)\n",
    "        \n",
    "    # Main colormesh plot\n",
    "    im_1 = ax.pcolormesh(cur_data_var['longitude'].data, \n",
    "                         cur_data_var['latitude'].data, \n",
    "                         NEODASS_data_to_plot_1day, \n",
    "                         cmap = color, \n",
    "                         norm=norm,\n",
    "                         transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Colorbar settings\n",
    "    cbar = plt.colorbar(im_1, ax = ax, label=xx_plot_cbar_label)\n",
    "\n",
    "    # Plot title\n",
    "    plot_title  = f'{xx_output_dir_name}' + f' {date_of_plot}'\n",
    "    ax.set_title(plot_title,fontsize = 24)\n",
    "\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Float plotting section\n",
    "    # Get the unique float names\n",
    "    unique_floats = full_position['float'].unique()\n",
    "\n",
    "    # Store legend handles and labels\n",
    "    legend_handles = []\n",
    "    \n",
    "    # Plot each float's positions\n",
    "    for float_name in unique_floats:\n",
    "        float_data = full_position[full_position['float'] == float_name].sort_values(by='JULD', ascending=False)  # Sort in descending order\n",
    "\n",
    "        # Get the colors and opacities for the points\n",
    "        rgba_color = to_rgba(float_colors.get(float_name, '#000000'))  # Default to black if not found\n",
    "        num_positions = len(float_data)\n",
    "        alphas = np.linspace(1, 0.1, min(num_positions, 9))  # Reverse the opacity gradient\n",
    "\n",
    "        # Plot the positions and lines, with the first 9 points have a decreasing alpha\n",
    "        for i, (index, row) in enumerate(float_data.iterrows()):\n",
    "            alpha = alphas[i] if i < 9 else 0.1\n",
    "            rgba_color_with_alpha = (*rgba_color[:3], alpha)\n",
    "            marker_edge_color     = (*rgba_color[:3], alpha)  # Marker edge color follows opacity gradient\n",
    "            ax.scatter(row['LONGITUDE'], row['LATITUDE'], color=rgba_color_with_alpha, edgecolor=marker_edge_color, transform=ccrs.PlateCarree(), zorder=3)\n",
    "\n",
    "            if i > 0:\n",
    "                prev_row = float_data.iloc[i - 1]\n",
    "                ax.plot([prev_row['LONGITUDE'], row['LONGITUDE']],\n",
    "                        [prev_row['LATITUDE'], row['LATITUDE']],\n",
    "                        color=rgba_color_with_alpha, transform=ccrs.PlateCarree(), zorder=2)\n",
    "                \n",
    "        # Create a proxy artist for each float\n",
    "        proxy = plt.Line2D([0], [0], linestyle='-', marker='o', color=float_colors.get(float_name, '#000000'), label=float_name)\n",
    "        legend_handles.append(proxy)\n",
    "    \n",
    "    sc3 = ax.scatter(-24,60,transform=ccrs.PlateCarree(), edgecolors='black', facecolors='none', marker='s')\n",
    "    ax.plot(circle_lons, circle_lats, transform=ccrs.PlateCarree(), color='black')\n",
    "    \n",
    "    gdf_1000.plot(ax=ax, transform=ccrs.PlateCarree(), linewidth=0.5, edgecolor='k', facecolor='none')\n",
    "    gdf_2000.plot(ax=ax, transform=ccrs.PlateCarree(), linewidth=0.3, edgecolor='k', facecolor='none')\n",
    "    \n",
    "    # Add Lat and Lon grid\n",
    "    gl = ax.gridlines(draw_labels = True, x_inline = False, y_inline = False, crs = ccrs.PlateCarree())\n",
    "    gl.top_labels   = False # suppress top labels\n",
    "    gl.right_labels = False # suppress right labels\n",
    "    \n",
    "    # Add legend in\n",
    "    deploy_point_proxy = plt.Line2D([0], [0], linestyle='none', marker='s', color='black', markersize=10, markerfacecolor='none', label='Deploy Point')\n",
    "    legend_handles.append(deploy_point_proxy)\n",
    "    ax.legend(handles=legend_handles, loc='lower left')\n",
    "\n",
    "    # Save output\n",
    "    save_dir = os.path.join(output_dir, f'{xx_output_dir_name}{\"_log\" if log_scaling else \"\"}')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    basename_suffix = base_name[:10]\n",
    "    filename = f'{xx_output_dir_name}{\"_log\" if log_scaling else \"\"}_{date_of_plot}_NEODASS.png'\n",
    "    plt.savefig(os.path.join(save_dir, filename))\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIOCarbon_Conda_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
