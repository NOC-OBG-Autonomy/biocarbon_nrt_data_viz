{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomy fleet visualization\n",
    "\n",
    "The objectives of this notebook are to :\n",
    "<ol>\n",
    "    <li> Download autonomy assets data </li>\n",
    "    <li> Show the current location of autonomy assets </li>\n",
    "    <li> Show the last profiles of the assets </li>\n",
    "    <li> Show the full depth/time transect of the assets </li>\n",
    "</ol>\n",
    "\n",
    "To run this notebook please refer to the readme of the github page (https://github.com/NOC-OBG-Autonomy/biocarbon_nrt_data_viz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download autonomy assets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "import xarray as xr\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the data repository structure. The data folder is not sync with git, so we need to create it if missing (i.e. first time your run this notebook on your computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data' folder already exists in the parent directory.\n",
      "'floats' directory already exists inside 'data' folder.\n",
      "'gliders' directory already exists inside 'data' folder.\n"
     ]
    }
   ],
   "source": [
    "def create_missing_directories():\n",
    "    # Define the path to the parent directory\n",
    "    parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "    # Check if 'data' folder exists in the parent directory\n",
    "    data_dir = os.path.join(parent_dir, 'data')\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        print(\"'data' folder created in the parent directory.\")\n",
    "    else:\n",
    "        print(\"'data' folder already exists in the parent directory.\")\n",
    "\n",
    "    # Check if 'floats' directory exists inside 'data' folder\n",
    "    floats_dir = os.path.join(data_dir, 'Floats')\n",
    "    if not os.path.exists(floats_dir):\n",
    "        os.makedirs(floats_dir)\n",
    "        print(\"'floats' directory created inside 'data' folder.\")\n",
    "    else:\n",
    "        print(\"'floats' directory already exists inside 'data' folder.\")\n",
    "\n",
    "    # Check if 'gliders' directory exists inside 'data' folder\n",
    "    gliders_dir = os.path.join(data_dir, 'Gliders')\n",
    "    if not os.path.exists(gliders_dir):\n",
    "        os.makedirs(gliders_dir)\n",
    "        print(\"'gliders' directory created inside 'data' folder.\")\n",
    "    else:\n",
    "        print(\"'gliders' directory already exists inside 'data' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_missing_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will visualize only test floats. One in the Icelandic bassin and the other in SO during the Custard cruise, which is a good test case as it has also gliders deployements.\n",
    "\n",
    "We don't automate in this script the retrieving of downloading url for the sake of simplicity. \n",
    "You can keep in mind that the list of float data and their repertory are findable here : https://data-argo.ifremer.fr/argo_synthetic-profile_index.tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmo_list = [6990636, 4903659, 3901581, 7902223, 3902261]\n",
    "#Float 1 = Flux1 float LOV\n",
    "float_1_url = 'https://data-argo.ifremer.fr/dac/coriolis/6990636/6990636_Sprof.nc'\n",
    "#Float 2 = Flux2 float LOV\n",
    "float_2_url = 'https://data-argo.ifremer.fr/dac/coriolis/4903659/4903659_Sprof.nc'\n",
    "#Float 3 = test float on Custard with glider next to it\n",
    "float_3_url = 'https://data-argo.ifremer.fr/dac/bodc/3901581/3901581_Sprof.nc'\n",
    "#Float 4 = test float on Custard with glider next to it\n",
    "float_4_url = 'https://data-argo.ifremer.fr/dac/coriolis/7902223/7902223_Sprof.nc'\n",
    "#Float 5 nearest to CIB\n",
    "float_5_url = 'https://data-argo.ifremer.fr/dac/aoml/3902261/3902261_Sprof.nc'\n",
    "\n",
    "#List the floats to plot\n",
    "floats_url = [float_1_url, float_2_url, float_3_url, float_4_url, float_5_url]\n",
    "\n",
    "#Assign the local float directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "floats_dir =  os.path.join(parent_dir, 'Data\\\\Floats')\n",
    "\n",
    "#Create floats filename\n",
    "floats_filenames = []\n",
    "for i in floats_url:\n",
    "    filename = floats_dir + '/' + i.rsplit('/', 1)[1]\n",
    "    floats_filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download floats data. We do it everytime so we are sure to work with a DAC up to date version. \n",
    "#We could check with the synthetic profile index if it is needed to download a update.\n",
    "for url, filename in zip(floats_url, floats_filenames):\n",
    "    urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for i in range(14):\n",
    "    url = 'https://data-argo.ifremer.fr/dac/bodc/3901581/profiles/SR3901581_0' + format(i + 1, '02d') + '.nc'\n",
    "    filename = floats_dir + '/' + url.rsplit('/', 1)[1]\n",
    "    urlretrieve(url, filename)\n",
    "    filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_position_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [], 'float' : int()})\n",
    "for file in filenames:\n",
    "    dat = xr.open_dataset(file)\n",
    "    dat = dat.rename({'CYCLE_NUMBER':'PROF_NUM'}).swap_dims({'N_PROF':'PROF_NUM'})\n",
    "    temp_df = dat[['LONGITUDE', 'LATITUDE', 'JULD']].to_dataframe().reset_index()\n",
    "    temp_df['float'] = 3901581\n",
    "    uk_position_df = pd.concat([uk_position_df, temp_df], ignore_index=True)\n",
    "    dat.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_position_df = uk_position_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot BGC-Argo locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Icelandic Bassin float\n",
    "\n",
    "There are 2 floats near the icelandic bassin. One on the north west that is currently leaving the bassin by the ridge and one that is coming by the south (deployed during APERO). For the second one there are some issues with the DAC so we are waiting for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [], 'float' : int()})\n",
    "for file, wmo in zip(floats_filenames, wmo_list):\n",
    "    dat = xr.open_dataset(file)\n",
    "    dat = dat.rename({'CYCLE_NUMBER':'PROF_NUM'}).swap_dims({'N_PROF':'PROF_NUM'})\n",
    "    temp_df = dat[['LONGITUDE', 'LATITUDE', 'JULD']].to_dataframe().reset_index()\n",
    "    temp_df['float'] = wmo\n",
    "    position_df = pd.concat([position_df, temp_df], ignore_index=True)\n",
    "    dat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = pd.read_csv(parent_dir + '/Plotting_tools/shared_data/rt_positions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_df = other_df[other_df['platform_id'] == 'lovuse031c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_float = pd.DataFrame({'PROF_NUM' : float_df['Unnamed: 0'], 'LONGITUDE' : float_df['lon'], 'LATITUDE' : float_df['lat'], 'float' : 1902695, 'JULD' : pd.to_datetime(float_df['date'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [position_df, missing_float]\n",
    "position_df = pd.concat(tables)\n",
    "position_df = pd.concat([position_df, uk_position_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "land_50m = cfeature.NaturalEarthFeature('physical', 'land', '50m',\n",
    "                                        edgecolor='k',\n",
    "                                        facecolor=cfeature.COLORS['land'])\n",
    "\n",
    "# Define data's extents I used an arbitrary extent that depicts the Icelandic Bassin\n",
    "min_lon = -33\n",
    "max_lon = -13\n",
    "min_lat = 55\n",
    "max_lat = 65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_directory = parent_dir + '/Data/' + \"ne_10m_bathymetry_all/\"\n",
    "def load_bathymetry(zip_file_url):\n",
    "    \"\"\"Read zip file from Natural Earth containing bathymetry shapefiles\"\"\"\n",
    "    # Download and extract shapefiles\n",
    "    import io\n",
    "    import zipfile\n",
    "\n",
    "    #r = requests.get(zip_file_url)\n",
    "    #z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    #z.extractall(bath_directory)\n",
    "\n",
    "    # Read shapefiles, sorted by depth\n",
    "    shp_dict = {}\n",
    "    files = glob(bath_directory + '*.shp')\n",
    "    assert len(files) > 0\n",
    "    files.sort()\n",
    "    depths = []\n",
    "    for f in files:\n",
    "        depth = '-' + f.split('_')[-1].split('.')[0]  # depth from file name\n",
    "        depths.append(depth)\n",
    "        bbox = (min_lon - 3, max_lon + 3,min_lat - 1, max_lat + 1)  # (x0, y0, x1, y1)\n",
    "        nei = shpreader.Reader(f, bbox=bbox)\n",
    "        shp_dict[depth] = nei\n",
    "    depths = np.array(depths)[::-1]  # sort from surface to bottom\n",
    "    return depths, shp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "depths_str, shp_dict = load_bathymetry(\n",
    "        'https://naturalearth.s3.amazonaws.com/' +\n",
    "        '10m_physical/ne_10m_bathymetry_all.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib\n",
    "position_df = position_df.sort_values(by=['JULD'])\n",
    "grouped = position_df.groupby('float')\n",
    "\n",
    "# Construct a discrete colormap with colors corresponding to each depth\n",
    "depths = depths_str.astype(int)\n",
    "N = len(depths)\n",
    "nudge = 0.01  # shift bin edge slightly to include data\n",
    "boundaries = [min(depths)] + sorted(depths+nudge)  # low to high\n",
    "norm = matplotlib.colors.BoundaryNorm(boundaries, N)\n",
    "blues_cm = matplotlib.colormaps['Blues_r'].resampled(N)\n",
    "colors_depths = blues_cm(norm(depths))\n",
    "\n",
    "# Set up plot\n",
    "# Initialize an empty figure and add an axis\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1,\n",
    "                    projection=ccrs.Mercator())\n",
    "\n",
    "# Set the map extent based on your latitude and longitude ranges\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Scatter plot\n",
    "sc = ax.scatter(position_df['LONGITUDE'], position_df['LATITUDE'], transform=ccrs.PlateCarree(), c = position_df['JULD'], zorder = 3)\n",
    "\n",
    "#set the plot color bar\n",
    "cbar = plt.colorbar(sc, ax = ax, label='Date')\n",
    "cbar.set_label('Date', rotation=270, labelpad=15)\n",
    "\n",
    "float_array = cbar.ax.get_yticks()\n",
    "formatted_date = np.vectorize(lambda x: datetime.fromtimestamp(float(x) / 1e9).strftime(\"%b %Y\"))(float_array)\n",
    "cbar.ax.set_yticklabels(formatted_date)\n",
    "\n",
    "for i, depth_str in enumerate(depths_str):\n",
    "    ax.add_geometries(shp_dict[depth_str].geometries(),\n",
    "                        crs=ccrs.PlateCarree(),\n",
    "                        color=colors_depths[i])\n",
    "\n",
    "for name, group in grouped:\n",
    "    group.plot(x='LONGITUDE', y='LATITUDE', ax=ax, transform=ccrs.PlateCarree(), label=name, zorder=2)\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(land_50m)\n",
    "ax.stock_img()\n",
    "\n",
    "# print a grid on it\n",
    "gl = ax.gridlines(draw_labels=True,x_inline=False,y_inline=False, crs=ccrs.PlateCarree())\n",
    "\n",
    "# Convert vector bathymetries to raster (saves a lot of disk space)\n",
    "# while leaving labels as vectors\n",
    "ax.set_rasterized(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_df.to_csv(parent_dir + '/Data/Floats/floats_location.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmo_list = [4903532, 1902637, 6990636, 3901581]\n",
    "float_files = [ f for f in os.listdir(parent_dir + '/Data/Floats') if any(str(wmo) in f for wmo in wmo_list)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [],'float' : int()})\n",
    "for file in float_files:\n",
    "    wmo = re.findall(r'\\d{7}', file)[0]\n",
    "    dat = xr.open_dataset(parent_dir + '/Data/Floats/' + file)\n",
    "    dat = dat.rename({'CYCLE_NUMBER':'PROF_NUM'}).swap_dims({'N_PROF':'PROF_NUM'})\n",
    "    if 'NITRATE_ADJUSTED' in dat.variables:\n",
    "        temp_df = dat[['LONGITUDE', 'LATITUDE', 'JULD', 'PRES', 'CHLA_ADJUSTED', 'PSAL_ADJUSTED', 'TEMP_ADJUSTED', 'NITRATE_ADJUSTED']].to_dataframe().reset_index()\n",
    "        temp_df['float'] = wmo\n",
    "        data_df = pd.concat([data_df, temp_df], ignore_index=True)\n",
    "        dat.close()\n",
    "    else :\n",
    "        print(f'{wmo} floats has no Nitrate')\n",
    "        temp_df = dat[['LONGITUDE', 'LATITUDE', 'JULD', 'PRES', 'CHLA_ADJUSTED', 'PSAL_ADJUSTED', 'TEMP_ADJUSTED']].to_dataframe().reset_index()\n",
    "        temp_df['float'] = wmo\n",
    "        data_df = pd.concat([data_df, temp_df], ignore_index=True)\n",
    "        dat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(parent_dir + '/Data/Floats/floats_nitrate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = xr.open_dataset(floats_filenames[1])\n",
    "df = dat[['JULD', 'PRES', 'TEMP', 'PSAL', 'CHLA_ADJUSTED', 'BBP700_ADJUSTED', 'DOXY_ADJUSTED']].to_dataframe()\n",
    "dat.close()\n",
    "df = df.reset_index().set_index('JULD', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "last_date = max(df['JULD'])\n",
    "\n",
    "last_df = df[df['JULD'] == last_date]\n",
    "early_df = df[df['JULD'] != last_date]\n",
    "early_df = early_df[early_df['JULD'] > pd.to_datetime('2024-01-01')]\n",
    "\n",
    "alphas = (early_df['N_PROF'] - min(early_df['N_PROF']))/(max(early_df['N_PROF']) - min(early_df['N_PROF']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiles\n",
    "\n",
    "### Temperature\n",
    "The temperature profiles. Last profile is in black, past float profiles are in grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastmonth_df = df[df['JULD'] > pd.to_datetime('2024-03-25')]\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc2 = ax.scatter( early_df['TEMP'], - (early_df['PRES']), alpha = alphas/5, c = 'grey')\n",
    "sc = ax.scatter( last_df['TEMP'], - (last_df['PRES']), c = 'black')\n",
    "\n",
    "#set the plot color bar\n",
    "#cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "#cbar.set_label('Julian Day', rotation=270, labelpad=15)\n",
    "ax.set_ylim([-1000,0])\n",
    "\n",
    "ax.set_xlabel('Degrees celcius')\n",
    "ax.set_ylabel('Depth')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n Temperature profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in the upper 500m during the last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc = ax.scatter( lastmonth_df['TEMP'], - (lastmonth_df['PRES']), c = lastmonth_df['JULD'])\n",
    "\n",
    "#set the plot color bar\n",
    "cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "cbar.set_label('Date', rotation=270, labelpad=15)\n",
    "float_array = cbar.ax.get_yticks()\n",
    "formatted_date = np.vectorize(lambda x: datetime.fromtimestamp(float(x) / 1e9).strftime(\"%d %b %Y\"))(float_array)\n",
    "cbar.ax.set_yticklabels(formatted_date)\n",
    "ax.set_ylim([-500,0])\n",
    "ax.set_xlim([6.5,12])\n",
    "\n",
    "ax.set_xlabel('Degrees celcius')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n Temperature profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chlorophyll a\n",
    "The chla profiles. Last profile is in black, past float profiles are in grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc2 = ax.scatter( early_df['CHLA_ADJUSTED'], - (early_df['PRES']), alpha = alphas, c = 'grey')\n",
    "sc = ax.scatter( last_df['CHLA_ADJUSTED'], - (last_df['PRES']), c = 'black')\n",
    "\n",
    "#set the plot color bar\n",
    "#cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "#cbar.set_label('Julian Day', rotation=270, labelpad=15)\n",
    "ax.set_ylim([-1000,0])\n",
    "ax.set_xlim([0,1.5])\n",
    "\n",
    "ax.set_xlabel('Chla (mg.m-3)')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n Chlorophyll-a profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in the upper 500m during the last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc = ax.scatter( lastmonth_df['CHLA_ADJUSTED'], - (lastmonth_df['PRES']), c = lastmonth_df['JULD'])\n",
    "\n",
    "#set the plot color bar\n",
    "cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "cbar.set_label('Date', rotation=270, labelpad=15)\n",
    "float_array = cbar.ax.get_yticks()\n",
    "formatted_date = np.vectorize(lambda x: datetime.fromtimestamp(float(x) / 1e9).strftime(\"%d %b %Y\"))(float_array)\n",
    "cbar.ax.set_yticklabels(formatted_date)\n",
    "ax.set_ylim([-500,0])\n",
    "ax.set_xlim([0,2])\n",
    "\n",
    "ax.set_xlabel('Chla (mg.m-3)')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n Chlorophyll-a profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BBP700 profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc2 = ax.scatter( early_df['BBP700_ADJUSTED'], - (early_df['PRES']), alpha = alphas/5, c = 'grey')\n",
    "sc = ax.plot( last_df['BBP700_ADJUSTED'], - (last_df['PRES']), c = 'black')\n",
    "\n",
    "#set the plot color bar\n",
    "#cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "#cbar.set_label('Julian Day', rotation=270, labelpad=15)\n",
    "ax.set_ylim([-1000,0])\n",
    "ax.set_xlim([0.0002,0.01])\n",
    "\n",
    "ax.set_xlabel('bbp (m-1)')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n BBP 700 profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in the upper 500m during the last month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc = ax.scatter( lastmonth_df['BBP700_ADJUSTED'], - (lastmonth_df['PRES']), c = lastmonth_df['JULD'])\n",
    "\n",
    "#set the plot color bar\n",
    "cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "cbar.set_label('Date', rotation=270, labelpad=15)\n",
    "float_array = cbar.ax.get_yticks()\n",
    "formatted_date = np.vectorize(lambda x: datetime.fromtimestamp(float(x) / 1e9).strftime(\"%d %b %Y\"))(float_array)\n",
    "cbar.ax.set_yticklabels(formatted_date)\n",
    "ax.set_ylim([-500,0])\n",
    "\n",
    "ax.set_xlabel('Bbp 700 (m-1)')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n BBP700 profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeseries of the ratio between bbp and Chla, in the first 5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_df = df[df['JULD'] > pd.to_datetime('2023-05-01')]\n",
    "timeseries_df = timeseries_df[timeseries_df['PRES'] < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = timeseries_df['BBP700_ADJUSTED'] / timeseries_df['CHLA_ADJUSTED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc2 = ax.scatter( timeseries_df['JULD'], ratio)\n",
    "\n",
    "#set the plot color bar\n",
    "#cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "#cbar.set_label('Julian Day', rotation=270, labelpad=15)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('BBP/Chla')\n",
    "# set the plot title\n",
    "ax.set_ylim([0, 0.01])\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n BBP/Chla time series : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc2 = ax.scatter( early_df['DOXY_ADJUSTED'], - (early_df['PRES']), alpha = alphas/5, c = 'grey')\n",
    "sc = ax.scatter( last_df['DOXY_ADJUSTED'], - (last_df['PRES']), c = 'black')\n",
    "\n",
    "#set the plot color bar\n",
    "#cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "#cbar.set_label('Julian Day', rotation=270, labelpad=15)\n",
    "ax.set_ylim([-1000,0])\n",
    "\n",
    "ax.set_xlabel('Dissolved Oxygen (umol.kg-1)')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n Dissolved oxygen profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sc = ax.scatter( lastmonth_df['DOXY_ADJUSTED'], - (lastmonth_df['PRES']), c = lastmonth_df['JULD'])\n",
    "\n",
    "#set the plot color bar\n",
    "cbar = plt.colorbar(sc, ax = ax, label='Julian day')\n",
    "cbar.set_label('Date', rotation=270, labelpad=15)\n",
    "float_array = cbar.ax.get_yticks()\n",
    "formatted_date = np.vectorize(lambda x: datetime.fromtimestamp(float(x) / 1e9).strftime(\"%d %b %Y\"))(float_array)\n",
    "cbar.ax.set_yticklabels(formatted_date)\n",
    "ax.set_ylim([-500,0])\n",
    "\n",
    "ax.set_xlabel('Dissolved oxygen (umol.kg-1)')\n",
    "ax.set_ylabel('Depth (m)')\n",
    "# set the plot title\n",
    "ax.set_title('Float wmo : ' + str(wmo) + \"\\n Dissolved oxygen profile : \" + last_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transect of the float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some time series visualisation of the float from 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(floats_filenames[0])\n",
    "data = data.rename({'CYCLE_NUMBER':'PROF_NUM'}).swap_dims({'N_PROF':'PROF_NUM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack NumPy array of datetimes to create a 2D grid\n",
    "time_2D = np.tile(data['JULD'].values,(len(data['N_LEVELS']),1)).T\n",
    "\n",
    "# Function for repetitive parts of plot\n",
    "def config_depth_section(cbar_label,title):\n",
    "  plt.ylim([0,250])\n",
    "  plt.gca().invert_yaxis()\n",
    "  plt.ylabel('Pressure (dbar)')\n",
    "  if 'Nitrate' in cbar_label: extend = 'min'\n",
    "  else:                       extend = 'neither'\n",
    "  plt.colorbar(label=cbar_label,extend=extend)\n",
    "  plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an array from NumPy datetime64 to Python float format\n",
    "def datetime_to_float(dt):\n",
    "  return (dt - np.datetime64('1900-01-01')) / np.timedelta64(1,'D')\n",
    "\n",
    "# Function to convert an array from Python float to NumPy datetime64 format\n",
    "def float_to_datetime(nums):\n",
    "  return (nums * np.timedelta64(1,'D')) + np.datetime64('1900-01-01')\n",
    "\n",
    "# Function to interpolate data from a specified float parameter to a uniform time and pressure grid\n",
    "def interpolate_depth_section(param_name,specify_qc_flags=None,pres_interval=1.0):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "      param_name: string with netCDF file parameter name (e.g., 'TEMP_ADJUSTED') to interpolate\n",
    "      specify_qc_flags: None to ignore QC flags\n",
    "                        or a list of QC flags (e.g., [1,2,3]) indicating which data to retain before interpolation\n",
    "      pres_interval: vertical resolution for interpolating pressure (z) axis (default: 1.0 dbar)\n",
    "  \n",
    "  Returns:\n",
    "      time_coord: 1-D NumPy array with original profile timestamps in np.datetime64 format\n",
    "      pres_coord: 1-D NumPy array with a uniform pressure (z) coordinate from 0 dbar to the deepest recorded\n",
    "                  pressure value, at a resolution of <pres_interval> dbar\n",
    "      time_grid: 2-D NumPy array with the meshed grid of time_coord\n",
    "      pres_grid: 2-D NumPy array with the meshed grid of pres_coord\n",
    "      param_gridded: 2-D NumPy array with the interpolated parameter values at the locations of time_grid and pres_grid\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # New grid points\n",
    "  time_coord = data['JULD'].values\n",
    "  time_coord = time_coord[(time_coord >= np.datetime64('2023-10-01'))]\n",
    "  pres_coord = np.arange(0,data['PRES'].max(),pres_interval)\n",
    "  time_grid, pres_grid = np.meshgrid(time_coord,pres_coord)\n",
    "  time_grid = datetime_to_float(time_grid)     # Convert from np.datetime64 to float\n",
    "\n",
    "  # 1-D (flattened) versions of old grids and parameter values\n",
    "  time_1D = np.tile(data['JULD'].values,(len(data['N_LEVELS']),1)).T.flatten()\n",
    "  pres_1D = data['PRES'].values.flatten()\n",
    "  param_1D = data[param_name].values.flatten()\n",
    "  if param_1D.dtype == object:         # If parameter is an array of QC flag data\n",
    "    param_1D = param_1D.astype(float)  # Convert QC flags from dtype 'object' to float\n",
    "    interp_method = 'nearest'          # Use nearest-neighbor interpolation for QC flags to avoid unwanted averaging\n",
    "  else:\n",
    "    interp_method = 'linear'           # Use bilinear interpolation for normal data fields\n",
    "\n",
    "  # Extract only values matching specified QC flags\n",
    "  if specify_qc_flags is not None:\n",
    "    qc_1D = data[param_name + '_QC'].values.astype(float).flatten()\n",
    "    qc_mask = np.tile(False,len(qc_1D))\n",
    "    for qc_flag in specify_qc_flags:\n",
    "      qc_mask = np.logical_or(qc_mask,qc_1D == qc_flag)\n",
    "    time_1D = time_1D[qc_mask]\n",
    "    pres_1D = pres_1D[qc_mask]\n",
    "    param_1D = param_1D[qc_mask]\n",
    "\n",
    "  # Remove NaN values before interpolation\n",
    "  time_1D = datetime_to_float(time_1D[~np.isnan(param_1D)])       # Convert from np.datetime64 to float\n",
    "  pres_1D = pres_1D[~np.isnan(param_1D)]\n",
    "  param_1D = param_1D[~np.isnan(param_1D)]\n",
    "\n",
    "  # Interpolate from irregular points to grid\n",
    "  param_gridded = interpolate.griddata((time_1D,pres_1D),param_1D,(time_grid,pres_grid),method=interp_method)\n",
    "\n",
    "  # Return coordinates, grid, and gridded data\n",
    "  return time_coord, pres_coord, float_to_datetime(time_grid), pres_grid, param_gridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "param_name = 'BBP700_ADJUSTED'\n",
    "time_coord, pres_coord, time_grid, pres_grid, param_gridded = interpolate_depth_section(param_name)\n",
    "\n",
    "# Plot depth section of upper ocean only\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.pcolormesh(time_grid,pres_grid,param_gridded)\n",
    "plt.ylim([0,1000])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel('Pressure (dbar)')\n",
    "plt.colorbar(label='{0} ({1})'.format(data[param_name].long_name,data[param_name].units))\n",
    "plt.title(data[param_name].long_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "param_name = 'TEMP_ADJUSTED'\n",
    "time_coord, pres_coord, time_grid, pres_grid, param_gridded = interpolate_depth_section(param_name)\n",
    "\n",
    "# Plot depth section of upper ocean only\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.pcolormesh(time_grid,pres_grid,param_gridded)\n",
    "plt.ylim([0,1000])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel('Pressure (dbar)')\n",
    "plt.colorbar(label='{0} ({1})'.format(data[param_name].long_name,data[param_name].units))\n",
    "plt.title(data[param_name].long_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "param_name = 'CHLA_ADJUSTED'\n",
    "time_coord, pres_coord, time_grid, pres_grid, param_gridded = interpolate_depth_section(param_name)\n",
    "\n",
    "# Plot depth section of upper ocean only\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.pcolormesh(time_grid,pres_grid,param_gridded)\n",
    "plt.ylim([0,1000])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel('Pressure (dbar)')\n",
    "plt.colorbar(label='{0} ({1})'.format(data[param_name].long_name,data[param_name].units))\n",
    "plt.title(data[param_name].long_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate data\n",
    "param_name = 'DOXY_ADJUSTED'\n",
    "time_coord, pres_coord, time_grid, pres_grid, param_gridded = interpolate_depth_section(param_name)\n",
    "\n",
    "# Plot depth section of upper ocean only\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.pcolormesh(time_grid,pres_grid,param_gridded)\n",
    "plt.ylim([0,1000])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel('Pressure (dbar)')\n",
    "plt.colorbar(label='{0} ({1})'.format(data[param_name].long_name,data[param_name].units))\n",
    "plt.title(data[param_name].long_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nrt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
