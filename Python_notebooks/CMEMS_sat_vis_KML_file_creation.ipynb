{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplekml import (Kml, OverlayXY, ScreenXY, Units, RotationXY,\n",
    "                       AltitudeMode, Camera)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### make_kml function\n",
    "def make_kml(llcrnrlon, llcrnrlat, urcrnrlon, urcrnrlat,\n",
    "             figs, colorbar=None, **kw):\n",
    "    \"\"\"TODO: LatLon bbox, list of figs, optional colorbar figure,\n",
    "    and several simplekml kw...\"\"\"\n",
    "\n",
    "    kml = Kml()\n",
    "    altitude = kw.pop('altitude', 2e7)\n",
    "    roll = kw.pop('roll', 0)\n",
    "    tilt = kw.pop('tilt', 0)\n",
    "    altitudemode = kw.pop('altitudemode', AltitudeMode.relativetoground)\n",
    "    camera = Camera(latitude=np.mean([urcrnrlat, llcrnrlat]),\n",
    "                    longitude=np.mean([urcrnrlon, llcrnrlon]),\n",
    "                    altitude=altitude, roll=roll, tilt=tilt,\n",
    "                    altitudemode=altitudemode)\n",
    "\n",
    "    kml.document.camera = camera\n",
    "    draworder = 0\n",
    "    for fig in figs:  # NOTE: Overlays are limited to the same bbox.\n",
    "        draworder += 1\n",
    "        ground = kml.newgroundoverlay(name='GroundOverlay')\n",
    "        ground.draworder = draworder\n",
    "        ground.visibility = kw.pop('visibility', 1)\n",
    "        ground.name = kw.pop('name', 'overlay')\n",
    "        ground.color = kw.pop('color', '9effffff')\n",
    "        ground.atomauthor = kw.pop('author', 'ocefpaf')\n",
    "        ground.latlonbox.rotation = kw.pop('rotation', 0)\n",
    "        ground.description = kw.pop('description', 'Matplotlib figure')\n",
    "        ground.gxaltitudemode = kw.pop('gxaltitudemode',\n",
    "                                       'clampToSeaFloor')\n",
    "        ground.icon.href = fig\n",
    "        ground.latlonbox.east = llcrnrlon\n",
    "        ground.latlonbox.south = llcrnrlat\n",
    "        ground.latlonbox.north = urcrnrlat\n",
    "        ground.latlonbox.west = urcrnrlon\n",
    "\n",
    "    if colorbar:  # Options for colorbar are hard-coded (to avoid a big mess).\n",
    "        screen = kml.newscreenoverlay(name='ScreenOverlay')\n",
    "        screen.icon.href = colorbar\n",
    "        screen.overlayxy = OverlayXY(x=0, y=0,\n",
    "                                     xunits=Units.fraction,\n",
    "                                     yunits=Units.fraction)\n",
    "        screen.screenxy = ScreenXY(x=0.015, y=0.075,\n",
    "                                   xunits=Units.fraction,\n",
    "                                   yunits=Units.fraction)\n",
    "        screen.rotationXY = RotationXY(x=0.5, y=0.5,\n",
    "                                       xunits=Units.fraction,\n",
    "                                       yunits=Units.fraction)\n",
    "        screen.size.x = 0\n",
    "        screen.size.y = 0\n",
    "        screen.size.xunits = Units.fraction\n",
    "        screen.size.yunits = Units.fraction\n",
    "        screen.visibility = 1\n",
    "\n",
    "    kmzfile = kw.pop('kmzfile', 'overlay.kmz')\n",
    "    kml.savekmz(kmzfile)\n",
    "#####\n",
    "\n",
    "##### gearth_fig function\n",
    "def gearth_fig(llcrnrlon, llcrnrlat, urcrnrlon, urcrnrlat, pixels=1024):\n",
    "    \"\"\"Return a Matplotlib `fig` and `ax` handles for a Google-Earth Image.\"\"\"\n",
    "    aspect = np.cos(np.mean([llcrnrlat, urcrnrlat]) * np.pi/180.0)\n",
    "    xsize = np.ptp([urcrnrlon, llcrnrlon]) * aspect\n",
    "    ysize = np.ptp([urcrnrlat, llcrnrlat])\n",
    "    aspect = ysize / xsize\n",
    "\n",
    "    if aspect > 1.0:\n",
    "        figsize = (10.0 / aspect, 10.0)\n",
    "    else:\n",
    "        figsize = (10.0, 10.0 * aspect)\n",
    "\n",
    "    if False:\n",
    "        plt.ioff()  # Make `True` to prevent the KML components from poping-up.\n",
    "    fig = plt.figure(figsize=figsize,\n",
    "                     frameon=False,\n",
    "                     dpi=pixels//10)\n",
    "    # KML friendly image.  If using basemap try: `fix_aspect=False`.\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.set_xlim(llcrnrlon, urcrnrlon)\n",
    "    ax.set_ylim(llcrnrlat, urcrnrlat)\n",
    "    return fig, ax\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules for figure creation\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish directories\n",
    "\n",
    "def create_missing_directories():\n",
    "    # Define the path to the parent directory\n",
    "    parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "    # Check if 'data' folder exists in the parent directory\n",
    "    data_dir = os.path.join(parent_dir, 'data')\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        print(\"'data' folder created in the parent directory.\")\n",
    "    else:\n",
    "        print(\"'data' folder already exists in the parent directory.\")\n",
    "\n",
    "    # Check if 'kmz' directory exists inside 'data' folder\n",
    "    kmz_dir = os.path.join(data_dir, 'kmz')\n",
    "    if not os.path.exists(kmz_dir):\n",
    "        os.makedirs(kmz_dir)\n",
    "        print(\"'KMZ' directory created inside 'data' folder.\")\n",
    "    else:\n",
    "        print(\"'KMZ' directory already exists inside 'data' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_missing_directories()\n",
    "\n",
    "# Establish directory locations\n",
    "\n",
    "parent_dir    = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir      = os.path.join(parent_dir, 'data')\n",
    "satellite_dir = os.path.join(data_dir, 'satellite')\n",
    "output_dir    = os.path.join(parent_dir, 'Output/kml')\n",
    "NEODASS_dir   = os.path.join(satellite_dir, 'NEODASS')\n",
    "floats_dir    = os.path.join(parent_dir, 'Data/Floats')\n",
    "kmz_dir       = os.path.join(parent_dir, 'Data/kmz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting preferences\n",
    "\n",
    "# Global\n",
    "min_lon = -35 #-35\n",
    "max_lon = -5 #-5\n",
    "min_lat = 55 #55\n",
    "max_lat = 66 #66\n",
    "\n",
    "# Float colors\n",
    "# For additional floats, add the name (as it appears in the 'Float_positions.csv') and color you'd like (as a hexcode)\n",
    "float_colors = {\n",
    "        '4903532':  '#B4184C',\n",
    "        'navis102': '#F5A300',\n",
    "        '1902637':  '#0000E0',\n",
    "        'navis101': '#FBFF1F'}\n",
    "\n",
    "# Define unique symbols for different object types\n",
    "object_symbols = {\n",
    "    'glider': 'o',\n",
    "    'Float': 's',\n",
    "    'Ship'  : '^'\n",
    "    # Add more object types and their symbols here\n",
    "}\n",
    "\n",
    "# DAC\n",
    "skip_dac             = False\n",
    "DAC_color            = 'spring'\n",
    "DAC_plot_as_log      = False # Default False\n",
    "DAC_plot_lim_max     = 0.5   # Default 5\n",
    "DAC_plot_lim_min     = 0   # Default 0\n",
    "\n",
    "# Surface Currents\n",
    "skip_ssc             = False\n",
    "SSC_color            = 'spring'\n",
    "SSC_plot_as_log      = False # Default False\n",
    "SSC_plot_lim_max     = 0.5   # Default 5\n",
    "SSC_plot_lim_min     = 0   # Default 0\n",
    "\n",
    "# 1000m currents\n",
    "skip_dwc             = False\n",
    "DWC_color            = 'spring'\n",
    "DWC_plot_as_log      = False\n",
    "DWC_plot_lim_max     = 0.5\n",
    "DWC_plot_lim_min     = 0\n",
    "\n",
    "# CHLA\n",
    "skip_chla            = False\n",
    "CHLA_color           = 'YlGnBu_r'\n",
    "CHLA_plot_as_log     = True # Default True\n",
    "CHLA_plot_lim_max    = 10   # Default 10\n",
    "CHLA_plot_lim_min    = 0.1  # Default 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Plotting most recent data from CMEMS\n",
    "## List most recent files\n",
    "\n",
    "# List to store matching file names\n",
    "matching_files = []\n",
    "\n",
    "# Loop through the files in the directory\n",
    "for filename in os.listdir(satellite_dir):\n",
    "    if filename.endswith('.nc'):\n",
    "        matching_files.append(filename)\n",
    "\n",
    "print(matching_files)\n",
    "\n",
    "## List variables from these files\n",
    "# Dictionary to store files by their base names (excluding '_a_' or '_b_') and key variables\n",
    "file_dict = {}\n",
    "\n",
    "for file in matching_files:\n",
    "    # Identify the base name by removing '_a' or '_b' if present\n",
    "    base_name = file\n",
    "    if base_name not in file_dict:\n",
    "        file_dict[base_name] = {}\n",
    "    filepath = os.path.join(satellite_dir, file)\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    variables = list(ds.data_vars.keys())\n",
    "\n",
    "    print(file)\n",
    "    print(variables)\n",
    "\n",
    "    key_variables = [var for var in variables if 'longitude' not in var.lower() and 'latitude' not in var.lower()]\n",
    "\n",
    "    if key_variables:\n",
    "        for key_variable in key_variables:\n",
    "            if file not in file_dict[base_name]:\n",
    "                file_dict[base_name][file] = {}\n",
    "            file_dict[base_name][file][key_variable] = {\n",
    "                'variable': key_variable,\n",
    "            }\n",
    "    else:\n",
    "        print(f\"No suitable key variable found in file: {file}\")\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "# Print the results\n",
    "for base_name, files in file_dict.items():\n",
    "    for file, key_variable in files.items():\n",
    "        print(f'File: {file}')\n",
    "        print(f'Base Name: {base_name}')\n",
    "        print(f'Key Variable: {key_variable}')\n",
    "\n",
    "    filepath  = os.path.join(satellite_dir, file)\n",
    "    dataset = xr.open_dataset(filepath)\n",
    "\n",
    "    # Print global attributes\n",
    "    print(\"Global attributes:\")\n",
    "    for attr_name, attr_value in dataset.attrs.items():\n",
    "        print(f\"  {attr_name}: {attr_value}\")\n",
    "\n",
    "    # Print variable attributes\n",
    "    print(\"\\nVariable attributes:\")\n",
    "    for var_name, var in dataset.variables.items():\n",
    "        print(f\"Variable: {var_name}\")\n",
    "        for attr_name, attr_value in var.attrs.items():\n",
    "            print(f\"  {attr_name}: {attr_value}\")\n",
    "\n",
    "# Initialize var_dict with categories as keys and empty dictionaries as values\n",
    "var_dict = {'chl': {}, 'temp': {}, 'sla': {}, 'adt': {}, 'bbp': {}, 'dissic': {}, 'ugos':{}, 'uo':{}, 'dwc':{}} \n",
    "\n",
    "for base_name, files in file_dict.items():\n",
    "    for file, variables in files.items():\n",
    "        contains_adt = False\n",
    "        contains_ugos = False\n",
    "        contains_uo = False\n",
    "        contains_dwc = False\n",
    "        \n",
    "        for key_variable, details in variables.items():\n",
    "            data_var = details['variable']\n",
    "            var_name_lower = data_var.lower()\n",
    "            \n",
    "            if 'chl' in var_name_lower and var_name_lower == 'chl':\n",
    "                var_dict['chl'][file] = data_var\n",
    "            elif 'temp' in var_name_lower:\n",
    "                var_dict['temp'][file] = data_var\n",
    "            elif 'sla' in var_name_lower:\n",
    "                var_dict['sla'][file] = data_var\n",
    "            elif 'adt' in var_name_lower:\n",
    "                var_dict['adt'][file] = data_var\n",
    "                contains_adt = True\n",
    "            elif 'bbp' in var_name_lower and var_name_lower == 'bbp':\n",
    "                var_dict['bbp'][file] = data_var\n",
    "            elif 'dissic' in var_name_lower and var_name_lower == 'dissic':\n",
    "                var_dict['dissic'][file] = data_var\n",
    "            elif 'ugos' in var_name_lower and var_name_lower == 'ugos':\n",
    "                contains_ugos = True\n",
    "            elif 'uo' in var_name_lower and var_name_lower == 'uo' and 'averaged' in base_name:\n",
    "                contains_uo = True\n",
    "            elif 'uo' in var_name_lower and var_name_lower == 'uo' and '1000m' in base_name:\n",
    "                contains_dwc = True\n",
    "                # Delay adding 'ugos' to var_dict until after the adt check\n",
    "\n",
    "        # After checking all variables in the file\n",
    "        if contains_ugos:\n",
    "            if contains_adt:\n",
    "                # Add to 'adt' category if the file contains both 'adt' and 'ugos'\n",
    "                var_dict['adt'][file] = data_var\n",
    "            else:\n",
    "                # Add to 'ugos' category if the file contains only 'ugos'\n",
    "                var_dict['ugos'][file] = data_var\n",
    "        if contains_uo:\n",
    "            var_dict['uo'][file] = data_var\n",
    "        if contains_dwc:\n",
    "            var_dict['dwc'][file] = data_var\n",
    "\n",
    "# We load shape files for bathymetry lines\n",
    "#first_line_path = 'c:\\\\Users\\\\flapet\\\\OneDrive - NOC\\\\Documents\\\\NRT_viz\\\\biocarbon_nrt_data_viz/Data/ne_10m_bathymetry_all/ne_10m_bathymetry_J_1000.shp'\n",
    "#second_line_path = 'c:\\\\Users\\\\flapet\\\\OneDrive - NOC\\\\Documents\\\\NRT_viz\\\\biocarbon_nrt_data_viz/Data/ne_10m_bathymetry_all/ne_10m_bathymetry_I_2000.shp'\n",
    "\n",
    "first_line_path  = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\data\\\\bathymetry\\\\ne_10m_bathymetry_J_1000.shp'\n",
    "second_line_path = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\data\\\\bathymetry\\\\ne_10m_bathymetry_I_2000.shp'\n",
    "\n",
    "gdf_1000 = gpd.read_file(first_line_path)\n",
    "gdf_2000 = gpd.read_file(second_line_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autonomy positions\n",
    "csv_file = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\Plotting_tools\\\\shared_data\\\\rt_positions.csv'  # Update this path\n",
    "df = pd.read_csv(csv_file)\n",
    "df['date'] = pd.to_datetime(df['date']) # Convert the 'time' column to datetime\n",
    "xx_day_offset = [-1, -2, -3, -4]\n",
    "\n",
    "for var_category, files in var_dict.items():\n",
    "    if var_category in ['adt', 'dwc', 'uo']:  \n",
    "        for day_offset in xx_day_offset:  # Plot the last day # Change this silly bit of code to be something more readable\n",
    "            if len(files) > 1:\n",
    "                data_vars = []\n",
    "                for file, data_var in files.items():\n",
    "                    cur_data_var = xr.open_dataset(os.path.join(satellite_dir, file))\n",
    "                    data_vars.append(cur_data_var[data_var].isel(time=day_offset))\n",
    "                aligned_data_vars = xr.align(*data_vars, join='outer')\n",
    "                combined_data_var = aligned_data_vars[0]\n",
    "                for var in aligned_data_vars[1:]:\n",
    "                    combined_data_var = combined_data_var.combine_first(var)\n",
    "                combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n",
    "                date_of_plot = str(combined_data_var['time'].data[0])[0:10]\n",
    "            elif len(files) == 1:\n",
    "                file, data_var = next(iter(files.items()))\n",
    "                cur_data_var = xr.open_dataset(os.path.join(satellite_dir, file))\n",
    "                date_of_plot = str(cur_data_var['time'].data[day_offset])[0:10]\n",
    "                combined_data_var_mean = cur_data_var[data_var].isel(time=day_offset).data\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            xx_plot_min = DAC_plot_lim_min\n",
    "            xx_plot_max = DAC_plot_lim_max\n",
    "            log_scaling = DAC_plot_as_log\n",
    "            norm = colors.LogNorm(vmin=xx_plot_min, vmax=xx_plot_max) if log_scaling else colors.Normalize(vmin=xx_plot_min, vmax=xx_plot_max)\n",
    "\n",
    "            # Units for colorbar\n",
    "            xx_plot_units = cur_data_var[data_var].attrs.get('units')\n",
    "            xx_plot_cbar_label = 'Sea surface velocity (' + xx_plot_units + ')'\n",
    "\n",
    "            # Clip the data within the specified range\n",
    "            data_to_plot_1day = combined_data_var_mean\n",
    "\n",
    "            # If the first dimension of the data is 1, remove it\n",
    "            if data_to_plot_1day.shape[0] == 1:\n",
    "                data_to_plot_1day = data_to_plot_1day[0]\n",
    "\n",
    "            # Extract longitudes and latitudes\n",
    "            longitudes = cur_data_var['longitude'].data\n",
    "            latitudes = cur_data_var['latitude'].data\n",
    "\n",
    "            if var_category in ['uo','dwc']:\n",
    "                ugos = cur_data_var['uo'].isel(time=day_offset).data\n",
    "                vgos = cur_data_var['vo'].isel(time=day_offset).data\n",
    "            if var_category == 'adt':\n",
    "                ugos = cur_data_var['ugos'].isel(time=day_offset).data\n",
    "                vgos = cur_data_var['vgos'].isel(time=day_offset).data\n",
    "\n",
    "            # Extracting latest lead float position\n",
    "            date_of_plot_filter = datetime.strptime(date_of_plot, '%Y-%m-%d')\n",
    "            df_filtered = df[df['date'] <= date_of_plot_filter]\n",
    "\n",
    "            legend_handles = []\n",
    "\n",
    "            # Process each unique object type\n",
    "            for obj_type, symbol in object_symbols.items():\n",
    "                if obj_type == 'Float':\n",
    "                    type_data = df_filtered[df_filtered['platform_type'] == obj_type]\n",
    "                    unique_names = type_data['platform_id'].unique()\n",
    "                    obj_data = type_data.sort_values(by='date', ascending=False)\n",
    "\n",
    "            # Define the bounds of the 2-degree square around the center\n",
    "            lon_min = obj_data['lon'].iloc[0] - 3\n",
    "            lon_max = obj_data['lon'].iloc[0] + 3\n",
    "            lat_min = obj_data['lat'].iloc[0] - 2\n",
    "            lat_max = obj_data['lat'].iloc[0] + 2\n",
    "\n",
    "            # Find the indices of the longitudes and latitudes within the bounds\n",
    "            lon_indices = np.where((longitudes >= lon_min) & (longitudes <= lon_max))[0]\n",
    "            lat_indices = np.where((latitudes >= lat_min) & (latitudes <= lat_max))[0]\n",
    "\n",
    "            # Extract the subset of data within the bounds\n",
    "            subsampled_longitudes = longitudes[lon_indices]\n",
    "            subsampled_latitudes = latitudes[lat_indices]\n",
    "            subsampled_ugos = ugos[np.ix_(lat_indices, lon_indices)]\n",
    "            subsampled_vgos = vgos[np.ix_(lat_indices, lon_indices)]\n",
    "\n",
    "            # Extract the lon and lat from the dataset only once\n",
    "            x = subsampled_longitudes\n",
    "            y = subsampled_latitudes\n",
    "\n",
    "            # From the U and V vector compute the speed, we use it as our colour map\n",
    "            u = subsampled_ugos\n",
    "            v = subsampled_vgos\n",
    "\n",
    "            #time_step = 6 * 3600  # Convert 6 hours to seconds\n",
    "\n",
    "            #U_km_per_6hr = u * time_step / 1000  # Convert from m/s to km/6hr\n",
    "            #V_km_per_6hr = v * time_step / 1000  # Convert from m/s to km/6hr\n",
    "            speed = np.sqrt(u**2 + v**2)\n",
    "\n",
    "            # Plot the current vectors field and the coastline\n",
    "            png_filename = 'quiver_plot.png'\n",
    "            pixels = 1024 * 10\n",
    "            fig, ax = gearth_fig(llcrnrlon=lon_min,\n",
    "                                 llcrnrlat=lat_min,\n",
    "                                 urcrnrlon=lon_max,\n",
    "                                 urcrnrlat=lat_max,\n",
    "                                 pixels=pixels)\n",
    "            im = ax.quiver(x, y, u, v,\n",
    "                           speed, angles='xy', scale_units='xy', \n",
    "                           cmap='spring', width=0.002, scale = 2,\n",
    "                           norm=norm) #scale = 0.00025)\n",
    "            ax.quiverkey(im, 0.86, 0.45, 0.2, \"0.2 m s^{-1}$\", labelpos='W')\n",
    "            ax.set_axis_off()\n",
    "            fig.savefig('overlay1.png', transparent=False, format='png')\n",
    "            #plt.savefig(png_filename, bbox_inches='tight', pad_inches=0)\n",
    "            #plt.close()\n",
    "\n",
    "            fig = plt.figure(figsize=(1.0, 4.0), facecolor=None, frameon=False)\n",
    "            ax = fig.add_axes([0.0, 0.05, 0.2, 0.9])\n",
    "            cb = fig.colorbar(im, cax=ax)\n",
    "            cb.set_label('Current velocity [m s^-1]', rotation=-90, color='k', labelpad=20)\n",
    "            fig.savefig('legend.png', transparent=False, format='png')  # Change transparent to True if your colorbar is not on space :)\n",
    "            \n",
    "            plot_prefix = 'NONE'\n",
    "\n",
    "            if var_category == 'adt':\n",
    "                plot_prefix = 'SC_'\n",
    "            elif var_category == 'uo':\n",
    "                plot_prefix = 'DAC_'\n",
    "            elif var_category == 'dwc':\n",
    "                plot_prefix = 'DWC_'\n",
    "\n",
    "            output_file_path = filepath = os.path.join(kmz_dir, plot_prefix + date_of_plot + '.kmz')\n",
    "\n",
    "            make_kml(llcrnrlon=lon_min, llcrnrlat=lat_min,\n",
    "                    urcrnrlon=lon_max, urcrnrlat=lat_max,\n",
    "                    figs=['overlay1.png'], colorbar='legend.png',\n",
    "                    kmzfile= output_file_path, name= plot_prefix + date_of_plot)\n",
    "            print('Made plot for ' + plot_prefix + date_of_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load autonomy positions\n",
    "csv_file = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\Plotting_tools\\\\shared_data\\\\rt_positions.csv'  # Update this path\n",
    "df = pd.read_csv(csv_file)\n",
    "df['date'] = pd.to_datetime(df['date']) # Convert the 'time' column to datetime\n",
    "xx_day_offset = [-1]\n",
    "\n",
    "for var_category, files in var_dict.items():\n",
    "    if var_category in ['chl']:  \n",
    "        for day_offset in xx_day_offset:  # Plot the last day # Change this silly bit of code to be something more readable\n",
    "            if len(files) > 1:\n",
    "                data_vars = []\n",
    "                for file, data_var in files.items():\n",
    "                    cur_data_var = xr.open_dataset(os.path.join(satellite_dir, file))\n",
    "                    data_vars.append(cur_data_var[data_var].isel(time=day_offset))\n",
    "                aligned_data_vars = xr.align(*data_vars, join='outer')\n",
    "                combined_data_var = aligned_data_vars[0]\n",
    "                for var in aligned_data_vars[1:]:\n",
    "                    combined_data_var = combined_data_var.combine_first(var)\n",
    "                combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n",
    "                date_of_plot = str(combined_data_var['time'].data[0])[0:10]\n",
    "            elif len(files) == 1:\n",
    "                file, data_var = next(iter(files.items()))\n",
    "                cur_data_var = xr.open_dataset(os.path.join(satellite_dir, file))\n",
    "                date_of_plot = str(cur_data_var['time'].data[day_offset])[0:10]\n",
    "                combined_data_var_mean = cur_data_var[data_var].isel(time=day_offset).data\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            xx_plot_min = CHLA_plot_lim_min\n",
    "            xx_plot_max = CHLA_plot_lim_max\n",
    "            log_scaling = CHLA_plot_as_log\n",
    "            norm = colors.LogNorm(vmin=xx_plot_min, vmax=xx_plot_max) if log_scaling else colors.Normalize(vmin=xx_plot_min, vmax=xx_plot_max)\n",
    "\n",
    "            # Units for colorbar\n",
    "            xx_plot_units = cur_data_var[data_var].attrs.get('units')\n",
    "            xx_plot_cbar_label = 'Sea surface velocity (' + xx_plot_units + ')'\n",
    "\n",
    "            # Clip the data within the specified range\n",
    "            data_to_plot_1day = combined_data_var_mean\n",
    "\n",
    "            # If the first dimension of the data is 1, remove it\n",
    "            if data_to_plot_1day.shape[0] == 1:\n",
    "                data_to_plot_1day = data_to_plot_1day[0]\n",
    "\n",
    "            # Extracting latest lead float position\n",
    "            date_of_plot_filter = datetime.strptime(date_of_plot, '%Y-%m-%d')\n",
    "            df_filtered = df[df['date'] <= date_of_plot_filter]\n",
    "\n",
    "            legend_handles = []\n",
    "\n",
    "            # Process each unique object type\n",
    "            for obj_type, symbol in object_symbols.items():\n",
    "                if obj_type == 'Float':\n",
    "                    type_data = df_filtered[df_filtered['platform_type'] == obj_type]\n",
    "                    unique_names = type_data['platform_id'].unique()\n",
    "                    obj_data = type_data.sort_values(by='date', ascending=False)\n",
    "\n",
    "            # Define the bounds of the 2-degree square around the center\n",
    "            lon_min = obj_data['lon'].iloc[0] - 3\n",
    "            lon_max = obj_data['lon'].iloc[0] + 3\n",
    "            lat_min = obj_data['lat'].iloc[0] - 2\n",
    "            lat_max = obj_data['lat'].iloc[0] + 2\n",
    "\n",
    "            # Find the indices of the longitudes and latitudes within the bounds\n",
    "            lon_indices = np.where((longitudes >= lon_min) & (longitudes <= lon_max))[0]\n",
    "            lat_indices = np.where((latitudes >= lat_min) & (latitudes <= lat_max))[0]\n",
    "\n",
    "            fig = plt.figure(figsize=(20, 10))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mercator())\n",
    "            ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "            pixels = 1024 * 10\n",
    "            \n",
    "            fig, ax = gearth_fig(llcrnrlon=lon_min,\n",
    "                                llcrnrlat=lat_min,\n",
    "                                urcrnrlon=lon_max,\n",
    "                                urcrnrlat=lat_max,\n",
    "                                pixels=pixels)\n",
    "\n",
    "            im = ax.pcolormesh(cur_data_var['longitude'].data, \n",
    "                               cur_data_var['latitude'].data, \n",
    "                               combined_data_var_mean, \n",
    "                               cmap=CHLA_color, \n",
    "                               norm=norm)\n",
    "            ax.set_axis_off()\n",
    "            fig.savefig('overlay1.png', transparent=False, format='png')\n",
    "\n",
    "            fig = plt.figure(figsize=(1.0, 4.0), facecolor=None, frameon=False)\n",
    "            ax = fig.add_axes([0.0, 0.05, 0.2, 0.9])\n",
    "            cb = fig.colorbar(im, cax=ax)\n",
    "            cb.set_label('Mean Dynamic Topography [m]', rotation=-90, color='k', labelpad=20)\n",
    "            fig.savefig('legend.png', transparent=False, format='png')  # Change transparent to True if your colorbar is not on space :)\n",
    "            \n",
    "            plot_prefix = 'NONE'\n",
    "\n",
    "            if var_category == 'chl':\n",
    "                plot_prefix = 'CHL_'\n",
    "\n",
    "            output_file_path = filepath = os.path.join(kmz_dir, plot_prefix + date_of_plot + '.kmz')\n",
    "\n",
    "            make_kml(llcrnrlon=lon_min, llcrnrlat=lat_min,\n",
    "                    urcrnrlon=lon_max, urcrnrlat=lat_max,\n",
    "                    figs=['overlay1.png'], colorbar='legend.png',\n",
    "                    kmzfile= output_file_path, name= plot_prefix + date_of_plot)\n",
    "            print('Made plot for ' + plot_prefix + date_of_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIOCarbon_Conda_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
