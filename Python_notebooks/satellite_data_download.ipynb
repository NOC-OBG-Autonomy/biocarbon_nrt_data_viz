{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Work\\OneDrive - NOC\\Documents\\PARTITRICS\\PARTITRICS_Python_Hans\\PARTITRICS_conda_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# I think a lot of these are unnecessary!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import gzip\n",
    "import copernicusmarine as cpm\n",
    "import re\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "import xarray as xr\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from scipy import interpolate\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data' folder already exists in the parent directory.\n",
      "'satellite' directory already exists inside 'data' folder.\n"
     ]
    }
   ],
   "source": [
    "def create_missing_directories():\n",
    "    # Define the path to the parent directory\n",
    "    parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "    # Check if 'data' folder exists in the parent directory\n",
    "    data_dir = os.path.join(parent_dir, 'data')\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        print(\"'data' folder created in the parent directory.\")\n",
    "    else:\n",
    "        print(\"'data' folder already exists in the parent directory.\")\n",
    "\n",
    "    # Check if 'satellite' directory exists inside 'data' folder\n",
    "    satellite_dir = os.path.join(data_dir, 'satellite')\n",
    "    if not os.path.exists(satellite_dir):\n",
    "        os.makedirs(satellite_dir)\n",
    "        print(\"'satellite' directory created inside 'data' folder.\")\n",
    "    else:\n",
    "        print(\"'satellite' directory already exists inside 'data' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_missing_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is the first time running copernicusmarine module on this machine, login using the terminal with:\n",
    "<code><pre>copernicusmarine login</code></pre>\n",
    "And enter your credentials. You will need an account already to do this. (https://data.marine.copernicus.eu/register) </br>\n",
    "This will store a credential file locally, you should only have to do this once per machine.\n",
    "\n",
    "When changing the catalogue search term, use the name of the product you'd like, e.g., from this domain, (https://data.marine.copernicus.eu/product/OCEANCOLOUR_ATL_BGC_L3_NRT_009_111/services), any of the named Dataset ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHL', 'CHL_uncertainty', 'flags']\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "catalogue_search_term = \"cmems_obs-oc_atl_bgc-plankton_nrt_l3-olci-300m_P1D\"\n",
    "\n",
    "satellite_catalogue = cpm.describe(contains=[catalogue_search_term], include_datasets=True, overwrite_metadata_cache=False) # Last command set to true ensures cache is up to date, i.e. browsing the latest catalogue. \n",
    "dataset_to_sample = satellite_catalogue['products'][0]['datasets'][0] # Define dataset to sample for next code block.\n",
    "vars_in_dataset   = [f\"{[variable['short_name'] for variable in service['variables']]}\" for service in dataset_to_sample['versions'][0]['parts'][0]['services']]\n",
    "\n",
    "dataset_to_extract = list(dataset_to_sample.values())\n",
    "dataset_to_extract = dataset_to_extract[0]\n",
    "\n",
    "vars_in_dataset = vars_in_dataset[0]\n",
    "vars_in_dataset_as_list = ast.literal_eval(vars_in_dataset)\n",
    "print(vars_in_dataset_as_list)\n",
    "var_to_extract = vars_in_dataset_as_list[0] # Index the variables you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note directories you wish to store data in, set bounds for time, space, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir    = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir      = os.path.join(parent_dir, 'data')\n",
    "satellite_dir = os.path.join(data_dir, 'satellite')\n",
    "\n",
    "variables_to_extract = [var_to_extract] # Input for variable must be list\n",
    "\n",
    "start_time = \"2024-04-01T00:00:00\" # Format time as YYYY-MM-DD\"T\"HH:MM:SS ,without T in parenthesis\n",
    "end_time   = \"2024-05-04T23:59:59\"\n",
    "\n",
    "min_depth = 0 # Primarily interested in surface values only. Will flag if outside of range of product\n",
    "max_depth = 1\n",
    "\n",
    "min_lon = -35 # Same lat/lons from autonomy visualisation, can be freely changed\n",
    "max_lon = -5\n",
    "min_lat = 55\n",
    "max_lat = 66\n",
    "\n",
    "saved_netCDF_as = \"CMEMS_Iceland_Basin_CHLA_April-May2024.nc\" # This changes the name of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2024-05-10T12:53:28Z - Dataset version was not specified, the latest one was selected: \"202303\"\n",
      "INFO - 2024-05-10T12:53:28Z - Dataset part was not specified, the first one was selected: \"default\"\n",
      "INFO - 2024-05-10T12:53:36Z - Service was not specified, the default one was selected: \"arco-geo-series\"\n",
      "WARNING - 2024-05-10T12:53:42Z - Some or all of your subset selection [55, 66] for the latitude dimension  exceed the dataset coordinates [20.002777099609375, 65.99722290039062]\n",
      "INFO - 2024-05-10T12:53:42Z - Downloading using service arco-geo-series...\n",
      "INFO - 2024-05-10T12:53:49Z - <xarray.Dataset> Size: 1GB\n",
      "Dimensions:    (time: 34, latitude: 1980, longitude: 5400)\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float32 8kB 55.0 55.01 55.01 ... 65.99 65.99 66.0\n",
      "  * longitude  (longitude) float32 22kB -35.0 -34.99 -34.99 ... -5.008 -5.003\n",
      "  * time       (time) datetime64[ns] 272B 2024-04-01 2024-04-02 ... 2024-05-04\n",
      "Data variables:\n",
      "    CHL        (time, latitude, longitude) float32 1GB dask.array<chunksize=(1, 1024, 512), meta=np.ndarray>\n",
      "Attributes: (12/92)\n",
      "    Conventions:                     CF-1.8, ACDD-1.3\n",
      "    DPM_reference:                   GC-UD-ACRI-PUG\n",
      "    IODD_reference:                  GC-UD-ACRI-PUG\n",
      "    acknowledgement:                 The Licensees will ensure that original ...\n",
      "    citation:                        The Licensees will ensure that original ...\n",
      "    cmems_product_id:                OCEANCOLOUR_ATL_BGC_L3_NRT_009_111\n",
      "    ...                              ...\n",
      "    time_coverage_resolution:        P1D\n",
      "    time_coverage_start:             2023-04-24T20:56:59Z\n",
      "    title:                           cmems_obs-oc_atl_bgc-plankton_nrt_l3-olc...\n",
      "    westernmost_longitude:           -46.0\n",
      "    westernmost_valid_longitude:     -46.0\n",
      "    copernicusmarine_version:        1.2.0\n",
      "INFO - 2024-05-10T12:53:49Z - Estimated size of the dataset file is 1387.511 MB.\n",
      "Do you want to proceed with download? [Y/n]:Error: invalid input\n",
      "Do you want to proceed with download? [Y/n]:INFO - 2024-05-10T12:55:01Z - Writing to local storage. Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7550/7550 [00:14<00:00, 537.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2024-05-10T12:55:16Z - Successfully downloaded to c:\\Users\\Work\\OneDrive - NOC\\Documents\\PARTITRICS\\PARTITRICS_Python_Hans\\biocarbon_nrt_data_viz\\data\\satellite\\CMEMS_Iceland_Basin_CHLA_April-May2024.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/Work/OneDrive - NOC/Documents/PARTITRICS/PARTITRICS_Python_Hans/biocarbon_nrt_data_viz/data/satellite/CMEMS_Iceland_Basin_CHLA_April-May2024.nc')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpm.subset(dataset_id=dataset_to_extract,\n",
    "  variables=variables_to_extract,\n",
    "  minimum_longitude= min_lon,\n",
    "  maximum_longitude= max_lon,\n",
    "  minimum_latitude= min_lat,\n",
    "  maximum_latitude= max_lat,\n",
    "  start_datetime=start_time,\n",
    "  end_datetime=end_time,\n",
    "  minimum_depth=min_depth,\n",
    "  maximum_depth=max_depth,\n",
    "  output_filename = saved_netCDF_as,\n",
    "  output_directory = satellite_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
