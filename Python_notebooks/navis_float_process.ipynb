{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir    = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir      = os.path.join(parent_dir, 'data')\n",
    "navis_dir = os.path.join(data_dir, 'navis')\n",
    "n101_folder = os.path.join(navis_dir, 'navis_101/csv_files')\n",
    "n102_folder = os.path.join(navis_dir, 'navis_102/csv_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the cal val for N101\n",
    "chl_dark = 51\n",
    "chl_slope = 0.001553\n",
    "\n",
    "beta_dark = 92\n",
    "beta_slope = 0.0000002485\n",
    "\n",
    "fdom_dark = 52\n",
    "fdom_slope = 0.01118\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_navis(filepath, float_ref):\n",
    "    raw_var = ['mtime', 'pnum', 'lat', 'lon', 'pres', 'T', 'C', 'oxy1', 'oxy2', 'mcoms1', 'mcoms2', 'mcoms3']\n",
    "    new_colnames = ['datetime', 'prof', 'lat', 'lon', 'pres', 'temp', 'conductivity', 'oxy1', 'oxy2', 'mcoms1', 'mcoms2', 'mcoms3']\n",
    "    df = pd.read_csv(filepath)\n",
    "    df_raw = df[raw_var]\n",
    "    df_raw.columns = new_colnames\n",
    "\n",
    "    df_computed = df_raw.copy()\n",
    "\n",
    "    df_computed.loc[:, 'Fchl'] = (df_raw['mcoms1'] - chl_dark) * chl_slope\n",
    "    df_computed.loc[:, 'beta'] = (df_raw['mcoms2'] - chl_dark) * chl_slope\n",
    "    df_computed.loc[:, 'fdom'] = (df_raw['mcoms3'] - chl_dark) * chl_slope\n",
    "\n",
    "    df_computed.loc[:, 'float'] = float_ref\n",
    "\n",
    "    return(df_computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_colnames = ['datetime', 'prof', 'lat', 'lon', 'pres', 'temp', 'conductivity', 'oxy1', 'oxy2', 'mcoms1', 'mcoms2', 'mcoms3']\n",
    "compiled_101 = pd.DataFrame(columns=new_colnames)\n",
    "for file in tqdm(os.listdir(n101_folder)):\n",
    "    filepath = os.path.join(n101_folder, file)\n",
    "    temp_df = open_navis(filepath, 'navis101')\n",
    "    compiled_101 = pd.concat([compiled_101, temp_df], ignore_index= True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the cal val for N102\n",
    "chl_dark = 50\n",
    "chl_slope = 0.002006\n",
    "\n",
    "beta_dark = 49\n",
    "beta_slope = 0.0000003524\n",
    "\n",
    "fdom_dark = 51\n",
    "fdom_slope = 0.006619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_colnames = ['datetime', 'prof', 'lat', 'lon', 'pres', 'temp', 'conductivity', 'oxy1', 'oxy2', 'mcoms1', 'mcoms2', 'mcoms3']\n",
    "compiled_102 = pd.DataFrame(columns=new_colnames)\n",
    "for file in tqdm(os.listdir(n102_folder)):\n",
    "    filepath = os.path.join(n102_folder, file)\n",
    "    temp_df = open_navis(filepath, 'navis102')\n",
    "    compiled_102 = pd.concat([compiled_102, temp_df], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navis_df = pd.concat([compiled_101, compiled_102])\n",
    "navis_position = navis_df[['datetime', 'prof', 'float', 'lon', 'lat']].drop_duplicates(subset = ['prof', 'float'])\n",
    "navis_df['JULD'] = pd.to_datetime(navis_df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navis_df.to_csv(os.path.join(navis_dir, 'merged_table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navis_position.columns = ['JULD', 'PROF_NUM', 'float', 'LONGITUDE', 'LATITUDE']\n",
    "navis_position['JULD'] = navis_position['JULD'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_datetime_column(df, column):\n",
    "    # Identify rows that do not match the expected datetime format\n",
    "    mask = df[column].str.contains(r'^\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}:\\d{2}$', regex=True)\n",
    "    \n",
    "    # Print the rows that are problematic\n",
    "    print(\"\\nProblematic entries:\")\n",
    "    print(df[~mask])\n",
    "    \n",
    "    # Filter out problematic rows or handle them accordingly\n",
    "    cleaned_df = df[mask].copy()\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_navis_position = navis_position.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_navis_position.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_navis_position['JULD'] = pd.to_datetime(cleaned_navis_position['JULD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmo_list = [4903532, 1902637]\n",
    "#Float 1 = test float in the Icelandic Bassin\n",
    "float_1_url = 'https://data-argo.ifremer.fr/dac/aoml/4903532/4903532_Sprof.nc'\n",
    "#Float 2 = test float on Custard with glider next to it\n",
    "float_2_url = 'https://data-argo.ifremer.fr/dac/coriolis/1902637/1902637_Sprof.nc'\n",
    "\n",
    "#List the floats\n",
    "floats_url = [float_1_url, float_2_url]\n",
    "\n",
    "#Assign the local float directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "floats_dir =  os.path.join(parent_dir, 'Data/Floats')\n",
    "\n",
    "#Create floats filename\n",
    "floats_filenames = []\n",
    "for i in floats_url:\n",
    "    filename = floats_dir + '/' + i.rsplit('/', 1)[1]\n",
    "    floats_filenames.append(filename)\n",
    "\n",
    "position_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [], 'float' : int()})\n",
    "last_position_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [], 'float' : int()})\n",
    "\n",
    "for file, wmo in zip(floats_filenames, wmo_list):\n",
    "    dat = xr.open_dataset(file)\n",
    "    dat = dat.rename({'CYCLE_NUMBER':'PROF_NUM'}).swap_dims({'N_PROF':'PROF_NUM'})\n",
    "    temp_df = dat[['LONGITUDE', 'LATITUDE', 'JULD']].to_dataframe().reset_index()\n",
    "    temp_df['float'] = wmo\n",
    "    last_temp_df = temp_df[temp_df['JULD'] == max(temp_df['JULD'])]\n",
    "\n",
    "    last_position_df = pd.concat([last_position_df, last_temp_df], ignore_index=True)\n",
    "    position_df = pd.concat([position_df, temp_df], ignore_index=True)\n",
    "    dat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navis_position['JULD'] = pd.to_datetime(navis_position['JULD'])\n",
    "full_position = pd.concat([position_df, navis_position], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "land_50m = cfeature.NaturalEarthFeature('physical', 'land', '50m',\n",
    "                                        edgecolor='k',\n",
    "                                        facecolor=cfeature.COLORS['land'])\n",
    "\n",
    "# Define data's extents I used an arbitrary extent that depicts the Icelandic Bassin\n",
    "min_lon = -35\n",
    "max_lon = -5\n",
    "min_lat = 55\n",
    "max_lat = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_directory = parent_dir + '/Data/' + \"ne_10m_bathymetry_all/\"\n",
    "def load_bathymetry(zip_file_url):\n",
    "    \"\"\"Read zip file from Natural Earth containing bathymetry shapefiles\"\"\"\n",
    "    # Download and extract shapefiles\n",
    "    import io\n",
    "    import zipfile\n",
    "\n",
    "    #r = requests.get(zip_file_url)\n",
    "    #z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    #z.extractall(bath_directory)\n",
    "\n",
    "    # Read shapefiles, sorted by depth\n",
    "    shp_dict = {}\n",
    "    files = glob(bath_directory + '*.shp')\n",
    "    assert len(files) > 0\n",
    "    files.sort()\n",
    "    depths = []\n",
    "    for f in files:\n",
    "        depth = '-' + f.split('_')[-1].split('.')[0]  # depth from file name\n",
    "        depths.append(depth)\n",
    "        bbox = (min_lon - 3, max_lon + 3,min_lat - 1, max_lat + 1)  # (x0, y0, x1, y1)\n",
    "        nei = shpreader.Reader(f, bbox=bbox)\n",
    "        shp_dict[depth] = nei\n",
    "    depths = np.array(depths)[::-1]  # sort from surface to bottom\n",
    "    return depths, shp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "depths_str, shp_dict = load_bathymetry(\n",
    "        'https://naturalearth.s3.amazonaws.com/' +\n",
    "        '10m_physical/ne_10m_bathymetry_all.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from datetime import datetime\n",
    "grouped = full_position.groupby('float')\n",
    "\n",
    "# Construct a discrete colormap with colors corresponding to each depth\n",
    "depths = depths_str.astype(int)\n",
    "N = len(depths)\n",
    "nudge = 0.01  # shift bin edge slightly to include data\n",
    "boundaries = [min(depths)] + sorted(depths+nudge)  # low to high\n",
    "norm = matplotlib.colors.BoundaryNorm(boundaries, N)\n",
    "blues_cm = matplotlib.colormaps['Blues_r'].resampled(N)\n",
    "colors_depths = blues_cm(norm(depths))\n",
    "\n",
    "# Set up plot\n",
    "# Initialize an empty figure and add an axis\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(1, 1, 1,\n",
    "                    projection=ccrs.Mercator())\n",
    "\n",
    "# Set the map extent based on your latitude and longitude ranges\n",
    "ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Scatter plot\n",
    "sc = ax.scatter(full_position['LONGITUDE'], full_position['LATITUDE'], transform=ccrs.PlateCarree(), c = full_position['JULD'], zorder = 3)\n",
    "\n",
    "#set the plot color bar\n",
    "cbar = plt.colorbar(sc, ax = ax, label='Date')\n",
    "cbar.set_label('Date', rotation=270, labelpad=15)\n",
    "\n",
    "float_array = cbar.ax.get_yticks()\n",
    "formatted_date = np.vectorize(lambda x: datetime.fromtimestamp(float(x) / 1e9).strftime(\"%b %Y\"))(float_array)\n",
    "cbar.ax.set_yticklabels(formatted_date)\n",
    "\n",
    "for i, depth_str in enumerate(depths_str):\n",
    "    ax.add_geometries(shp_dict[depth_str].geometries(),\n",
    "                        crs=ccrs.PlateCarree(),\n",
    "                        color=colors_depths[i])\n",
    "\n",
    "for name, group in grouped:\n",
    "    group.plot(x='LONGITUDE', y='LATITUDE', ax=ax, transform=ccrs.PlateCarree(), label=name, zorder=2)\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(land_50m)\n",
    "ax.stock_img()\n",
    "\n",
    "# print a grid on it\n",
    "gl = ax.gridlines(draw_labels=True,x_inline=False,y_inline=False, crs=ccrs.PlateCarree())\n",
    "\n",
    "# Convert vector bathymetries to raster (saves a lot of disk space)\n",
    "# while leaving labels as vectors\n",
    "ax.set_rasterized(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nrt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
