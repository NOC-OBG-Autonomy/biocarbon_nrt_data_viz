{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib.colors as colors\n",
    "import geopandas as gpd\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from glob import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import sys\n",
    "import math\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import LinearRing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish directory locations \n",
    "\n",
    "parent_dir    = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir      = os.path.join(parent_dir, 'data')\n",
    "satellite_dir = os.path.join(data_dir, 'satellite')\n",
    "output_dir    = os.path.join(parent_dir, 'Output/sat_plot')\n",
    "NEODASS_dir   = os.path.join(satellite_dir, 'NEODASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting preferences\n",
    "\n",
    "# Global\n",
    "min_lon = -35\n",
    "max_lon = -5\n",
    "min_lat = 55\n",
    "max_lat = 66\n",
    "\n",
    "# CHLA\n",
    "CHLA_color           = 'YlGnBu_r'\n",
    "CHLA_plot_as_log     = True # Default True\n",
    "CHLA_plot_lim_max    = 10   # Default 10\n",
    "CHLA_plot_lim_min    = 0.1  # Default 0.1\n",
    "\n",
    "# SST\n",
    "SST_color            = 'YlOrRd'\n",
    "SST_plot_as_log      = False # Default False\n",
    "SST_plot_lim_max     = 15    # Default 15\n",
    "SST_plot_lim_min     = 5     # Default 5\n",
    "\n",
    "# SSH\n",
    "SSH_color            = 'RdBu'\n",
    "SSH_plot_as_log      = False # Default False\n",
    "SSH_plot_lim_max     = 0.5   # Default  0.5\n",
    "SSH_plot_lim_min     = -0.5  # Default -0.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the length of one degree of longitude at a given latitude\n",
    "def lon_deg_length(latitude):\n",
    "    # Convert latitude from degrees to radians\n",
    "    lat_rad = np.radians(latitude)\n",
    "    \n",
    "    # Earth radius in kilometers\n",
    "    earth_radius_km = 6371.0\n",
    "    \n",
    "    # Calculate the length of one degree of longitude at the given latitude using the Haversine formula\n",
    "    lon_deg_length_km = np.cos(lat_rad) * (2 * np.pi * earth_radius_km) / 360.0\n",
    "    \n",
    "    return lon_deg_length_km\n",
    "\n",
    "# Function to create a circle geometry\n",
    "def create_circle(lon, lat, radius_km):\n",
    "    # Calculate the length of one degree of longitude at the given latitude\n",
    "    lon_deg_length_km = lon_deg_length(lat)\n",
    "    \n",
    "    # Convert radius from km to degrees\n",
    "    radius_deg = radius_km / lon_deg_length_km\n",
    "    \n",
    "    # Create a Point object for the center of the circle\n",
    "    center_point = Point(lon, lat)\n",
    "    \n",
    "    # Create a LinearRing object representing the circle\n",
    "    circle = center_point.buffer(radius_deg)\n",
    "    \n",
    "    return circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanshil\\AppData\\Local\\Temp\\ipykernel_31716\\1457570185.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  last_position_df = pd.concat([last_position_df, last_temp_df], ignore_index=True)\n",
      "C:\\Users\\hanshil\\AppData\\Local\\Temp\\ipykernel_31716\\1457570185.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  position_df = pd.concat([position_df, temp_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve float locations, load in bathymetry data\n",
    "\n",
    "wmo_list = [4903532, 1902637]\n",
    "#Float 1 = test float in the Icelandic Bassin\n",
    "float_1_url = 'https://data-argo.ifremer.fr/dac/aoml/4903532/4903532_Sprof.nc'\n",
    "#Float 2 = test float on Custard with glider next to it\n",
    "float_2_url = 'https://data-argo.ifremer.fr/dac/coriolis/1902637/1902637_Sprof.nc'\n",
    "\n",
    "#List the floats\n",
    "floats_url = [float_1_url, float_2_url]\n",
    "\n",
    "#Assign the local float directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "floats_dir = os.path.join(parent_dir, 'Data/Floats')\n",
    "\n",
    "#Create floats filename\n",
    "floats_filenames = []\n",
    "for i in floats_url:\n",
    "    filename = floats_dir + '/' + i.rsplit('/', 1)[1]\n",
    "    floats_filenames.append(filename)\n",
    "\n",
    "for url, filename in zip(floats_url, floats_filenames):\n",
    "    urlretrieve(url, filename)\n",
    "\n",
    "#We will loop through the float files, we create two dataframe. One with all the positions from both floats, and one with only the last positions from both floats.\n",
    "#Since we know plot the last position of the float at the date of the plot, the second one is not needed.\n",
    "\n",
    "#Create empty df\n",
    "position_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [], 'float' : int()})\n",
    "last_position_df = pd.DataFrame({'PROF_NUM' : str(), 'LONGITUDE' : [], 'LATITUDE' : [], 'float' : int()})\n",
    "\n",
    "for file, wmo in zip(floats_filenames, wmo_list):\n",
    "    dat = xr.open_dataset(file)\n",
    "    dat = dat.rename({'CYCLE_NUMBER':'PROF_NUM'}).swap_dims({'N_PROF':'PROF_NUM'})\n",
    "    temp_df = dat[['LONGITUDE', 'LATITUDE', 'JULD']].to_dataframe().reset_index()\n",
    "    temp_df['float'] = wmo\n",
    "    last_temp_df = temp_df[temp_df['JULD'] == max(temp_df['JULD'])]\n",
    "\n",
    "    last_position_df = pd.concat([last_position_df, last_temp_df], ignore_index=True)\n",
    "    position_df = pd.concat([position_df, temp_df], ignore_index=True)\n",
    "    dat.close()\n",
    "position_df = position_df[position_df['LATITUDE'] > min_lat]\n",
    "\n",
    "######\n",
    "\n",
    "# Load shape files for bathymetry:\n",
    "#first_line_path = 'c:\\\\Users\\\\flapet\\\\OneDrive - NOC\\\\Documents\\\\NRT_viz\\\\biocarbon_nrt_data_viz/Data/ne_10m_bathymetry_all/ne_10m_bathymetry_J_1000.shp'\n",
    "#second_line_path = 'c:\\\\Users\\\\flapet\\\\OneDrive - NOC\\\\Documents\\\\NRT_viz\\\\biocarbon_nrt_data_viz/Data/ne_10m_bathymetry_all/ne_10m_bathymetry_I_2000.shp'\n",
    "\n",
    "first_line_path  = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\data\\\\bathymetry\\\\ne_10m_bathymetry_J_1000.shp'\n",
    "second_line_path = 'C:\\\\Users\\\\hanshil\\\\Documents\\\\GitHub\\\\biocarbon_nrt_data_viz\\\\data\\\\bathymetry\\\\ne_10m_bathymetry_I_2000.shp'\n",
    "\n",
    "gdf_1000 = gpd.read_file(first_line_path)\n",
    "gdf_2000 = gpd.read_file(second_line_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cmems_sea_level-sla-1d-20240524_20240524-nrt.nc', 'olci_a_1km-CHL_OC4ME-1d-20240524_20240524-nrt.nc', 'olci_b_1km-CHL_OC4ME-1d-20240524_20240524-nrt.nc', 'slstr_a-sea_surface_temperature-1d-20240524_20240524-nrt.nc', 'slstr_b-sea_surface_temperature-1d-20240524_20240524-nrt.nc', 'viirs_noaa20-chl_oc5ci-1d-20240524_20240524-nrt.nc', 'viirs_suomi-chl_oc5_pic-1d-20240524_20240524-nrt.nc']\n",
      "File: cmems_sea_level-sla-1d-20240524_20240524-nrt.nc\n",
      "Base Name: cmems_sea_level-sla-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: sla\n",
      "File: olci_a_1km-CHL_OC4ME-1d-20240524_20240524-nrt.nc\n",
      "Base Name: olci__1km-CHL_OC4ME-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: CHL_OC4ME\n",
      "File: olci_b_1km-CHL_OC4ME-1d-20240524_20240524-nrt.nc\n",
      "Base Name: olci__1km-CHL_OC4ME-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: CHL_OC4ME\n",
      "File: slstr_a-sea_surface_temperature-1d-20240524_20240524-nrt.nc\n",
      "Base Name: slstr_-sea_surface_temperature-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: sea_surface_temperature\n",
      "File: slstr_b-sea_surface_temperature-1d-20240524_20240524-nrt.nc\n",
      "Base Name: slstr_-sea_surface_temperature-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: sea_surface_temperature\n",
      "File: viirs_noaa20-chl_oc5ci-1d-20240524_20240524-nrt.nc\n",
      "Base Name: viirs_noaa20-chl_oc5ci-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: chl_oc5ci\n",
      "File: viirs_suomi-chl_oc5_pic-1d-20240524_20240524-nrt.nc\n",
      "Base Name: viirs_suomi-chl_oc5_pic-1d-20240524_20240524-nrt.nc\n",
      "Key Variable: chl_oc5\n"
     ]
    }
   ],
   "source": [
    "### Plotting most recent data from NEODASS\n",
    "\n",
    "## List most recent files\n",
    "\n",
    "# Get yesterday's date in the required format\n",
    "yesterday = (datetime.now() - timedelta(days=2)).strftime('%Y%m%d')\n",
    "\n",
    "# List to store matching file names\n",
    "matching_files = []\n",
    "\n",
    "# Loop through the files in the directory\n",
    "for filename in os.listdir(NEODASS_dir):\n",
    "    if filename.endswith('.nc') and f'-1d-{yesterday}_{yesterday}-' in filename:\n",
    "        matching_files.append(filename)\n",
    "\n",
    "print(matching_files)\n",
    "\n",
    "## List variables from these files\n",
    "\n",
    "# Dictionary to store files by their base names (excluding '_a_' or '_b_') and key variables\n",
    "file_dict = {}\n",
    "\n",
    "for file in matching_files:\n",
    "    # Identify the base name by removing '_a' or '_b' if present\n",
    "    base_name = file.replace('_a', '_').replace('_b', '_')\n",
    "    if base_name not in file_dict:\n",
    "        file_dict[base_name] = {}\n",
    "    filepath  = os.path.join(NEODASS_dir, file)\n",
    "    ds        = xr.open_dataset(filepath)\n",
    "    variables = list(ds.data_vars.keys())\n",
    "    \n",
    "    # Find the key variable excluding 'longitude' and 'latitude'\n",
    "    key_variable = None\n",
    "    for var in variables:\n",
    "        if 'longitude' not in var.lower() and 'latitude' not in var.lower():\n",
    "            key_variable = var\n",
    "            break\n",
    "    \n",
    "    if key_variable:\n",
    "        file_dict[base_name][file] = key_variable\n",
    "    \n",
    "    ds.close()\n",
    "\n",
    "# Print the results\n",
    "for base_name, files in file_dict.items():\n",
    "    for file, key_variable in files.items():\n",
    "        print(f'File: {file}')\n",
    "        print(f'Base Name: {base_name}')\n",
    "        print(f'Key Variable: {key_variable}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanshil\\AppData\\Local\\Temp\\ipykernel_31716\\1324976813.py:24: RuntimeWarning: Mean of empty slice\n",
      "  combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n",
      "C:\\Users\\hanshil\\AppData\\Local\\Temp\\ipykernel_31716\\1324976813.py:24: RuntimeWarning: Mean of empty slice\n",
      "  combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Plotting loops\n",
    "\n",
    "for base_name, files in file_dict.items():\n",
    "\n",
    "    # Check if there are multiple files associated with the base name\n",
    "    if len(files) > 1:\n",
    "\n",
    "        # List of data variables to be combined\n",
    "        data_vars = []\n",
    "        \n",
    "        # Loop through each file and collect data variables\n",
    "        for file, data_var in files.items():\n",
    "            # Perform data preparation for files with the same base name\n",
    "            cur_data_var = xr.open_dataset(os.path.join(NEODASS_dir, f'{file}'))\n",
    "            data_vars.append(cur_data_var[data_var])\n",
    "        \n",
    "        # Align data variables from all files\n",
    "        aligned_data_vars = xr.align(*data_vars, join='outer')\n",
    "        \n",
    "        # Combine aligned data variables\n",
    "        combined_data_var = aligned_data_vars[0]\n",
    "        for var in aligned_data_vars[1:]:\n",
    "            combined_data_var      = combined_data_var.combine_first(var)\n",
    "            combined_data_var_mean = np.nanmean(combined_data_var, axis=0)\n",
    "            date_of_plot = str(combined_data_var['time'].data[0])[:10]\n",
    "            \n",
    "    else: # Single satellite file\n",
    "\n",
    "        for file, data_var in files.items():   \n",
    "            cur_data_var = xr.open_dataset(os.path.join(NEODASS_dir, f'{file}'))\n",
    "            date_of_plot = str(cur_data_var['time'].data[0])[:10]\n",
    "\n",
    "    # Initialise figure\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax  = fig.add_subplot(1, 1, 1, projection=ccrs.Mercator())\n",
    "    ax.set_extent([min_lon, max_lon, min_lat, max_lat], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Set plot settings based on variable\n",
    "    var_name_lower = data_var.lower()\n",
    "    if 'chl' in var_name_lower:\n",
    "        units_nonstandard = cur_data_var[data_var].attrs.get('units_nonstandard')\n",
    "        xx_plot_cbar_label = 'Chlorophyll (' + units_nonstandard + ')'\n",
    "        xx_plot_min = CHLA_plot_lim_min\n",
    "        xx_plot_max = CHLA_plot_lim_max\n",
    "        color       = CHLA_color\n",
    "        log_scaling = CHLA_plot_as_log\n",
    "        xx_output_dir_name = 'Chla'\n",
    "    elif 'temp' in var_name_lower:\n",
    "        units_nonstandard = cur_data_var[data_var].attrs.get('units_nonstandard')\n",
    "        if units_nonstandard == 'kelvin':\n",
    "            degree_sign = u'\\N{DEGREE SIGN}'\n",
    "            xx_plot_cbar_label = 'Sea Surface Temperature ('+degree_sign+'C)'\n",
    "            if len(files) > 1:\n",
    "                combined_data_var_mean -= 273.15\n",
    "            else:\n",
    "                cur_data_var[data_var] = cur_data_var[data_var] - 273.15 # Convert from Kelvin to Celsius\n",
    "            xx_plot_min = SST_plot_lim_min\n",
    "            xx_plot_max = SST_plot_lim_max\n",
    "            color       = SST_color\n",
    "            log_scaling = SST_plot_as_log\n",
    "            xx_output_dir_name = 'SST'\n",
    "    elif 'sla' in var_name_lower:\n",
    "        units_nonstandard = cur_data_var[data_var].attrs.get('units')\n",
    "        xx_plot_cbar_label = 'Sea level anamoly (' + units_nonstandard + ')'\n",
    "        xx_plot_min = SSH_plot_lim_min\n",
    "        xx_plot_max = SSH_plot_lim_max\n",
    "        color       = SSH_color\n",
    "        log_scaling = SSH_plot_as_log\n",
    "        xx_output_dir_name = 'SLA'\n",
    "    if log_scaling:\n",
    "        norm = colors.LogNorm(vmin = xx_plot_min, vmax = xx_plot_max)\n",
    "    else:\n",
    "        norm = colors.Normalize(vmin = xx_plot_min, vmax = xx_plot_max)\n",
    "\n",
    "    if len(files) > 1:\n",
    "    # Clip data for clean colormap\n",
    "        NEODASS_data_to_plot_1day = np.clip(combined_data_var_mean.data,xx_plot_min,xx_plot_max)\n",
    "    else:\n",
    "        NEODASS_data_to_plot_1day = np.clip(cur_data_var[data_var].data[0,:],xx_plot_min,xx_plot_max)\n",
    "        \n",
    "    # Main colormesh plot\n",
    "    im_1 = ax.pcolormesh(cur_data_var['longitude'].data, \n",
    "                         cur_data_var['latitude'].data, \n",
    "                         NEODASS_data_to_plot_1day, \n",
    "                         cmap = color, \n",
    "                         norm=norm,\n",
    "                         transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Colorbar settings\n",
    "    cbar = plt.colorbar(im_1, ax = ax, label=xx_plot_cbar_label)\n",
    "\n",
    "    # Plot title\n",
    "    plot_title  = f'{xx_output_dir_name}' + f' {date_of_plot}'\n",
    "    ax.set_title(plot_title,fontsize = 24)\n",
    "\n",
    "    # Filter the float position data to highlight the last position at the date of the plot\n",
    "    last_pos_df = position_df[position_df['JULD'] <= date_of_plot]\n",
    "    red_point   = last_pos_df[last_pos_df['JULD'] == max(last_pos_df['JULD'])]\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Ploting the float positions\n",
    "    sc  = ax.scatter(last_pos_df['LONGITUDE'], last_pos_df['LATITUDE'], transform=ccrs.PlateCarree(), c = 'black', zorder = 3) # Scatter plot of the previous positions\n",
    "    sc2 = ax.scatter(red_point['LONGITUDE'], red_point['LATITUDE'], transform=ccrs.PlateCarree(), c = 'red', zorder = 4) # Scatter plot of the most recent position in red\n",
    "    sc3 = ax.scatter(-24,60,transform=ccrs.PlateCarree(), edgecolors='black', facecolors='none', marker='s') # Mark deploy point\n",
    "\n",
    "    circle_geometry = create_circle(-24, 60, 130)\n",
    "    circle_patch = ax.add_geometries([circle_geometry], crs=ccrs.PlateCarree(), transform=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "    \n",
    "    # Plot the bathymetry at 1000 and 2000m\n",
    "    gdf_1000.plot(ax=ax, transform=ccrs.PlateCarree(), linewidth=0.5, edgecolor='k', facecolor='none')\n",
    "    gdf_2000.plot(ax=ax, transform=ccrs.PlateCarree(), linewidth=0.3, edgecolor='k', facecolor='none')\n",
    "    \n",
    "    # Add Lat and Lon grid\n",
    "    gl = ax.gridlines(draw_labels = True, x_inline = False, y_inline = False, crs = ccrs.PlateCarree())\n",
    "    gl.top_labels   = False # suppress top labels\n",
    "    gl.right_labels = False # suppress right labels\n",
    "    \n",
    "    # Create a proxy artist for the legend\n",
    "    proxy = plt.Line2D([0], [0], linestyle='none', marker='s', color='black', markersize=10, markerfacecolor='none')\n",
    "    # Add a legend with the proxy artist\n",
    "    ax.legend([proxy], ['Deploy Point'], loc='lower left')\n",
    "\n",
    "    # Save directory based on variable\n",
    "    save_dir = os.path.join(output_dir, f'{xx_output_dir_name}{\"_log\" if log_scaling else \"\"}')\n",
    "\n",
    "    # Check if the directory exists, if not create it\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Format filename\n",
    "    filename = f'{xx_output_dir_name}{\"_log\" if log_scaling else \"\"}_{date_of_plot}_{base_name}.png'\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(save_dir, filename))\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIOCarbon_Conda_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
